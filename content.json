{"meta":{"title":"BADWOLFBAY","subtitle":"Run,You Clever Boy!","description":"RUN,YOU CLEVER BOY","author":"badwolf","url":"http://www.badwolfbay.cn"},"pages":[{"title":"","date":"2017-09-21T14:12:55.000Z","updated":"2017-09-21T14:12:55.000Z","comments":true,"path":"404.html","permalink":"http://www.badwolfbay.cn/404.html","excerpt":"","text":""},{"title":"categories","date":"2017-09-19T14:24:41.000Z","updated":"2017-09-20T05:25:55.000Z","comments":false,"path":"categories/index.html","permalink":"http://www.badwolfbay.cn/categories/index.html","excerpt":"","text":""},{"title":"首页","date":"2017-08-22T05:56:03.000Z","updated":"2017-09-18T14:08:12.000Z","comments":true,"path":"e9-a6-96-e9-a1-b5-trashed/index.html","permalink":"http://www.badwolfbay.cn/e9-a6-96-e9-a1-b5-trashed/index.html","excerpt":"","text":"欢迎来到您的站点！这是您的主页，也就是大多数访客第一次造访时看到的页面。"},{"title":"示例页面","date":"2017-08-18T11:21:01.000Z","updated":"2017-09-18T14:08:12.000Z","comments":true,"path":"sample-page-trashed/index.html","permalink":"http://www.badwolfbay.cn/sample-page-trashed/index.html","excerpt":"","text":"这是示范页面。页面和博客文章不同，它的位置是固定的，通常会在站点导航栏显示。很多用户都创建一个“关于”页面，向访客介绍自己。例如： 欢迎！我白天是个邮递员，晚上就是个有抱负的演员。这是我的博客。我住在天朝的帝都，有条叫做Jack的狗。 ……或这个： XYZ Doohickey公司成立于1971年，自从建立以来，我们一直向社会贡献着优秀doohickies。我们的公司总部位于天朝魔都，有着超过两千名员工，对魔都政府税收有着巨大贡献。 而您，作为一个WordPress用户，我们建议您访问控制板，删除本页面，然后添加您自己的页面。祝您使用愉快！"},{"title":"tags","date":"2017-09-19T14:26:55.000Z","updated":"2017-09-20T05:28:06.000Z","comments":false,"path":"tags/index.html","permalink":"http://www.badwolfbay.cn/tags/index.html","excerpt":"","text":""},{"title":"Blog","date":"2017-08-22T05:56:03.000Z","updated":"2017-09-18T14:08:12.000Z","comments":true,"path":"blog/index.html","permalink":"http://www.badwolfbay.cn/blog/index.html","excerpt":"","text":""}],"posts":[{"title":"eletron-vuex-not-working","slug":"eletron-vuex-not-working","date":"2020-03-15T15:31:49.000Z","updated":"2020-03-15T16:06:55.860Z","comments":true,"path":"2020/03/15/eletron-vuex-not-working/","link":"","permalink":"http://www.badwolfbay.cn/2020/03/15/eletron-vuex-not-working/","excerpt":"","text":"在基于electron开发时使用vuex的dispatch方法传值无效 1vue.$store.dispatch(VUEX_ACTION_UPDATE_INFO, info) 并且不报任何错误.经查找是vuex-electron的问题. 解决方法1:在store/index.js中去掉createSharedMutations 12345678export default new Vuex.Store(&#123; modules, plugins: [ createPersistedState(), createSharedMutations() // 注释掉这一行 ], strict: process.env.NODE_ENV !== &apos;production&apos;&#125;) 这是因为 vuex-electron 引入了一个用于多进程间共享 Vuex Store 的状态的插件.如果没有多进程交互的需求，完全可以不引入这个插件. 解决方法2https://github.com/vue-electron/vuex-electron#installation 看第 3 条： In case if you enabled createSharedMutations() plugin you need to create an instance of store in the main process. To do it just add this line into your main process (for example src/main.js): 12&gt; import './path/to/your/store'&gt; 这种时候就不能用第一种方法来解决问题了。 找到 /src/main/index.js，在前面加上一句： 1import '../renderer/store'","categories":[{"name":"electron","slug":"electron","permalink":"http://www.badwolfbay.cn/categories/electron/"}],"tags":[{"name":"electron","slug":"electron","permalink":"http://www.badwolfbay.cn/tags/electron/"},{"name":"vue","slug":"vue","permalink":"http://www.badwolfbay.cn/tags/vue/"}]},{"title":"manjaro-desktop","slug":"manjaro-desktop","date":"2020-03-13T15:00:49.000Z","updated":"2020-03-13T15:42:02.430Z","comments":true,"path":"2020/03/13/manjaro-desktop/","link":"","permalink":"http://www.badwolfbay.cn/2020/03/13/manjaro-desktop/","excerpt":"","text":"先晒一下manjaro截图 因为经常使用python,在win下开发很难受,所以将笔记本系统换成了manjaro,在执行镜像,安装系统,安装软件,美化和字体渲染方面也遇到了很多问题.晒一下截图.并记录一下遇到的大的问题,等有时间统一整理记录. openvpn配置文件是openssl1.0版本编译,并修改qopenvpn图形界面 Electron版本的docker客户端图形工具开发 字体渲染,在设置中设置字体后软件字体不生效问题","categories":[{"name":"manjaro","slug":"manjaro","permalink":"http://www.badwolfbay.cn/categories/manjaro/"}],"tags":[{"name":"manjaro","slug":"manjaro","permalink":"http://www.badwolfbay.cn/tags/manjaro/"}]},{"title":"Java String详解","slug":"java-string","date":"2018-05-09T03:12:53.000Z","updated":"2018-05-09T03:14:40.000Z","comments":true,"path":"2018/05/09/java-string/","link":"","permalink":"http://www.badwolfbay.cn/2018/05/09/java-string/","excerpt":"Java中的String是经常使用的类，但是String中有很多需要学习的东西 1.不可变性 从最开始学习String时，就一直说String的类型是不可变的，但是从来没有深究。如果看String源码会发现 String类是final修饰的，使用者并不能通过继承来修改String类中的内容 String内部维护了一个final修饰的char类型的数组 char类型的数组虽然是引用类型，但是new String时使用Arrays.copyOf来避免使用者通过修改数组内容来修改String 使用replace,substring是，都是重新new String 2.equals 在Java中使用equals来比较两个对象是否相等 123public boolean equals(Object obj) &#123; return (this == obj);&#125; Object中的源码中显示如果没有重写equals，比较的就是两个对象的内存地址是否相等。String重写了equals方法123456789101112131415161718192021public boolean equals(Object anObject) &#123; if (this == anObject) &#123; return true; &#125; if (anObject instanceof String) &#123; String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false;&#125; 从源码中可以发现 如果两个String对象地址相同，则肯定相等。 两个对象地址不同，如果数组的长度相等，并且数组中每个值都相等，则两个字符串相等。","text":"Java中的String是经常使用的类，但是String中有很多需要学习的东西 1.不可变性 从最开始学习String时，就一直说String的类型是不可变的，但是从来没有深究。如果看String源码会发现 String类是final修饰的，使用者并不能通过继承来修改String类中的内容 String内部维护了一个final修饰的char类型的数组 char类型的数组虽然是引用类型，但是new String时使用Arrays.copyOf来避免使用者通过修改数组内容来修改String 使用replace,substring是，都是重新new String 2.equals 在Java中使用equals来比较两个对象是否相等 123public boolean equals(Object obj) &#123; return (this == obj);&#125; Object中的源码中显示如果没有重写equals，比较的就是两个对象的内存地址是否相等。String重写了equals方法123456789101112131415161718192021public boolean equals(Object anObject) &#123; if (this == anObject) &#123; return true; &#125; if (anObject instanceof String) &#123; String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false;&#125; 从源码中可以发现 如果两个String对象地址相同，则肯定相等。 两个对象地址不同，如果数组的长度相等，并且数组中每个值都相等，则两个字符串相等。 3.StringBuilder +在做变量拼接时其实是用的StringBuilder.append()方法，所以当使用+和StringBuilder.append()时，其实效率没有太大的差别，但是如果把+放在循环中时做字符串循环拼接时,+的效率就会低很多，如 1234String result = &quot;&quot;;for (int i = 0; i&lt;1000 ; i++)&#123; result += i;&#125; 因为每次循环都会产生一个StringBuilder对象,通过StringBuilder的append方法完成字符串+的操作，在循环过程中，result的长度越来越长，占用的空间越来越大，就比较容易出现OOM。 4.字符串常量池 JVM为了提高性能和减少内存开销，在实例化字符串常量的时候进行了一些优化 通过字面量声明的字符串直接保存到常量池中，如String s = “test”; 当创建字符串时，首先检查字符串常量池中是否存在该字符串 Q1: 下面分别创建了几个对象 12String s1 = \"test1\";String s2 = new String(\"test2\"); A： s1创建了一个字符串对象；s2可能创建一个对象，也可能创建两个对象，当字符串常量池中不存在”test2”时，在字符串常量池中创建，同时在堆中创建对象,对象指向字符串常量池的”test2”。 可以用String.intern()方法将字符串保存到常量池中，常量池底层使用StringTable保存字符串的引用在使用intern方法时： 如果常量池中已经存在当前字符串，将直接返回当前字符串 如果常量池中不存在当前字符串，将该字符串添加到字符串常量池中，然后返回该字符串的引用 12345String a = new StringBuilder(&quot;test&quot;).append(&quot;string&quot;).toString();System.out.println(a.intern() == a);String b = new StringBuilder(&quot;ja&quot;).append(&quot;va&quot;).toString();System.out.println(b.intern() == b); 上面代码在JDK1.6和JDK1.7上运行会分别得到不同的结果JDK1.6下：false, falseJDK1.7下：true, false 是由于JDK1.6中字符串常量池在永久代中，从JDK1.7开始字符串常量池移到了堆中。 JDK1.6中的intern1.变量a分配在heap上，a.intern()指向的是永久代中的引用，和a指向的不是同一个引用，所以返回false2.对于b同理，指向的并不是同一个引用 JDK1.7以后的intern1.在做intern操作时，如果StringTable已经存在相等的字符串，返回StringTable中的字符串引用，如果不存在，复制字符串的引用到常量池中，然后返回。所以对于变量a，一开始StringTable中不存在teststring的引用，所以JVM会复制变量a的引用到StringTable中，所以a.intern()和a其实是同一个字符串的引用，返回true。2.对于变量b,一开始就存在java字符串，b.intern()返回的是StringTable中的引用，和b指向的并不是同一个，所以返回false。","categories":[{"name":"Java","slug":"Java","permalink":"http://www.badwolfbay.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.badwolfbay.cn/tags/Java/"}]},{"title":"记一次Dubbo调用失败的错误","slug":"window-tomcat-start","date":"2018-01-30T01:12:00.000Z","updated":"2018-01-30T01:34:10.000Z","comments":true,"path":"2018/01/30/window-tomcat-start/","link":"","permalink":"http://www.badwolfbay.cn/2018/01/30/window-tomcat-start/","excerpt":"","text":"应用程序作为provider注册到Dubbo的注册中心后，作为提供者一直被消费者访问不到，报出一个超时链接的错误。 &ensp;&ensp;一开始怀疑是网络问题(提供者将自身的服务注册到注册中心后，消费者会从注册中心获取提供者的真实地址和端口，从而通过RPC进行远程调用，所以提供者的地址信息会在消费者的客户端缓存一份)，可是从消费者到注册者的网络环境能ping通，telnet其提供者的端口也是通的。 &ensp;&ensp;从浏览器中通过Http的方式访问提供者的接口，浏览器就一直处于访问的挂起状态，得不到返回信息。同样后台也看不到任何报错信息，怀疑是不是Dubbo的问题，可是检查注册中心后发现一切正常，其他服务都能够正常访问。 &ensp;&ensp;最后在部署程序时发现Tomcat的控制台日志一直卡住。悲催的因为程序只能部署在Windows上，之前一直在Linux下部署,只有开发在Windows下开发，可是从来没有遇到这种问题。Tomcat是通过双击startup.bat启动的，后来决定从cmd中启动试一下，程序居然可以访问了!!! &ensp;&ensp;百度后发现原来是Windows下Console设置的问题。在Console中右键，选择属性，然后再选项中勾掉编辑选项的快速编辑模式，默认是打勾的，去掉那个勾勾，然后再确认就可以了。Windows下的大坑啊。。。折腾了一下午！","categories":[{"name":"Java","slug":"Java","permalink":"http://www.badwolfbay.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.badwolfbay.cn/tags/Java/"},{"name":"Dubbo","slug":"Dubbo","permalink":"http://www.badwolfbay.cn/tags/Dubbo/"},{"name":"Windows","slug":"Windows","permalink":"http://www.badwolfbay.cn/tags/Windows/"},{"name":"Tomcat","slug":"Tomcat","permalink":"http://www.badwolfbay.cn/tags/Tomcat/"}]},{"title":"Spring+Mybatis分库分表总结","slug":"multiresouce-sharding","date":"2018-01-18T03:38:01.000Z","updated":"2018-01-18T08:21:21.000Z","comments":true,"path":"2018/01/18/multiresouce-sharding/","link":"","permalink":"http://www.badwolfbay.cn/2018/01/18/multiresouce-sharding/","excerpt":"收到一个用户需求要求时时展现填报信息，之前项目使用的数据库是MySQL，但是由于数据量较大而且计算过程复杂，所以决定将数据放到Oracle中利用存储过程计算，这样就需要项目同时连接Oracle和MySQL数据库。下边简单总结下分库分表 分表当一个表的数据量很大以后，业务上就需要根据规则对数据库进行水平切分，如注册用户表user_01,user_02等，但是当数据库表进行切分以后，程序就需要根据规格进行相应的处理。利用Mybatis的interceptor可以实现根据路由规则去操作相应的数据库，开源的有Shardbatis实现。但是sharding只能区分一个数据源中的不同表，并不能根据规则切换数据源。 分库如果想连接多个数据库，需要配置两个数据源，如 123456&lt;bean id=\"oracleDataSource\" class=\"org.apache.commons.dbcp.BasicDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"oracle.jdbc.driver.OracleDriver\" /&gt; &lt;property name=\"url\" value=\"$&#123;oracle.db.url&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;oracle.db.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;oracle.db.password&#125;\" /&gt; &lt;/bean&gt; 利用AbstractRoutingDataSource. 在配置文件中加入DynamicDataSource配置，其中可以配置多个数据源链接和默认的链接 12345678910&lt;bean id=&quot;dataSource&quot; class=&quot;com.xxx.core.dataSource.DynamicDataSource&quot; &gt; &lt;property name=&quot;targetDataSources&quot;&gt; &lt;map key-type=&quot;java.lang.String&quot;&gt; &lt;entry value-ref=&quot;dataSource1&quot; key=&quot;dataSource1&quot;&gt;&lt;/entry&gt; &lt;entry value-ref=&quot;dataSource2&quot; key=&quot;dataSource2&quot;&gt;&lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;property name=&quot;defaultTargetDataSource&quot; ref=&quot;dataSource1&quot;&gt; &lt;/property&gt; &lt;/bean&gt; 然后继承AbstractRoutingDataSource,该方法中实现数据库的动态切换。 123456public class DynamicDataSource extends AbstractRoutingDataSource&#123; @Override protected Object determineCurrentLookupKey() &#123; return DataSourceContextHolder.getDataSourceType(); &#125;&#125; 定义一个可以设置当前线程的变量的工具类，用于设置对应的数据源名称。由于Spring的Bean是单例的，需要将数据源放入ThreadLocal中来避免线程安全的问题。123456789101112public class DataSourceContextHolder &#123; private static final ThreadLocal&lt;String&gt; contextHolder = new ThreadLocal&lt;String&gt;(); public static void setDataSourceType(String dataSourceType) &#123; contextHolder.set(dataSourceType); &#125; public static String getDataSourceType() &#123; return contextHolder.get(); &#125; public static void clearDataSourceType() &#123; contextHolder.remove(); &#125; &#125; 也可以利用AOP+Annotation来实现基于注解的数据库动态切换。","text":"收到一个用户需求要求时时展现填报信息，之前项目使用的数据库是MySQL，但是由于数据量较大而且计算过程复杂，所以决定将数据放到Oracle中利用存储过程计算，这样就需要项目同时连接Oracle和MySQL数据库。下边简单总结下分库分表 分表当一个表的数据量很大以后，业务上就需要根据规则对数据库进行水平切分，如注册用户表user_01,user_02等，但是当数据库表进行切分以后，程序就需要根据规格进行相应的处理。利用Mybatis的interceptor可以实现根据路由规则去操作相应的数据库，开源的有Shardbatis实现。但是sharding只能区分一个数据源中的不同表，并不能根据规则切换数据源。 分库如果想连接多个数据库，需要配置两个数据源，如 123456&lt;bean id=\"oracleDataSource\" class=\"org.apache.commons.dbcp.BasicDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"oracle.jdbc.driver.OracleDriver\" /&gt; &lt;property name=\"url\" value=\"$&#123;oracle.db.url&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;oracle.db.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;oracle.db.password&#125;\" /&gt; &lt;/bean&gt; 利用AbstractRoutingDataSource. 在配置文件中加入DynamicDataSource配置，其中可以配置多个数据源链接和默认的链接 12345678910&lt;bean id=&quot;dataSource&quot; class=&quot;com.xxx.core.dataSource.DynamicDataSource&quot; &gt; &lt;property name=&quot;targetDataSources&quot;&gt; &lt;map key-type=&quot;java.lang.String&quot;&gt; &lt;entry value-ref=&quot;dataSource1&quot; key=&quot;dataSource1&quot;&gt;&lt;/entry&gt; &lt;entry value-ref=&quot;dataSource2&quot; key=&quot;dataSource2&quot;&gt;&lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;property name=&quot;defaultTargetDataSource&quot; ref=&quot;dataSource1&quot;&gt; &lt;/property&gt; &lt;/bean&gt; 然后继承AbstractRoutingDataSource,该方法中实现数据库的动态切换。 123456public class DynamicDataSource extends AbstractRoutingDataSource&#123; @Override protected Object determineCurrentLookupKey() &#123; return DataSourceContextHolder.getDataSourceType(); &#125;&#125; 定义一个可以设置当前线程的变量的工具类，用于设置对应的数据源名称。由于Spring的Bean是单例的，需要将数据源放入ThreadLocal中来避免线程安全的问题。123456789101112public class DataSourceContextHolder &#123; private static final ThreadLocal&lt;String&gt; contextHolder = new ThreadLocal&lt;String&gt;(); public static void setDataSourceType(String dataSourceType) &#123; contextHolder.set(dataSourceType); &#125; public static String getDataSourceType() &#123; return contextHolder.get(); &#125; public static void clearDataSourceType() &#123; contextHolder.remove(); &#125; &#125; 也可以利用AOP+Annotation来实现基于注解的数据库动态切换。 直接配置两个数据源。这种方式简单粗暴，配置多个数据源直接访问不同的数据库，但是数据库的事务会存在问题，不能同时保证多个数据库的事务。配置时遇到了spring-mybatis的一个大坑。 天真的以为同时配置两套datasource,sessionFactory,transaction,mapperscannerconfigurer就能用了，如 12345678910111213141516171819&lt;bean id=\"oracleDataSource\" class=\"org.apache.commons.dbcp.BasicDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"oracle.jdbc.driver.OracleDriver\" /&gt; &lt;property name=\"url\" value=\"$&#123;oracle.db.url&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;oracle.db.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;oracle.db.password&#125;\" /&gt;&lt;/bean&gt;&lt;bean id=\"oracleSqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"oracleDataSource\" /&gt; &lt;property name=\"mapperLocations\" value=\"classpath:com/xxx/oracle/mapper/*.xml\" /&gt;&lt;/bean&gt;&lt;bean id=\"oracleTransactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"oracleDataSource\" /&gt;&lt;/bean&gt;&lt;tx:annotation-driven transaction-manager=\"oracleTransactionManager\" proxy-target-class=\"true\" /&gt;&lt;bean id=\"oracleMapperScannerConfigurer\" class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"com.xxx.oracle\" /&gt; &lt;/bean&gt; 但是并没有。。。一直抱一个Mapped Statements collection does not contain value for的错误，直接将mybatis的xml放到另一个数据源下就会报表不存在的错误，事实证明配置的Oracle数据源在Mybatis中并没有生效。在stackoverflow上也并没有找到相关问题的解。无意中看到一篇文章，原文地址 https://www.iflym.com/index.php/code/201211010001.html 才发现spring-mybatis的一个大坑。原文指出在MapperFactoryBean的父类SqlSessionDaoSupport123456789101112@Autowired(required = false)public final void setSqlSessionFactory(SqlSessionFactory sqlSessionFactory) &#123; if (!this.externalSqlSession) &#123; this.sqlSession = new SqlSessionTemplate(sqlSessionFactory); &#125;&#125; @Autowired(required = false)public final void setSqlSessionTemplate(SqlSessionTemplate sqlSessionTemplate) &#123; this.sqlSession = sqlSessionTemplate; this.externalSqlSession = true;&#125; 你绝对想不到，因为经过Autowired的处理，MapperFactoryBean即会运行setSqlSessionFactory方法，也会运行setSqlSessionTemplate方法。而更让人郁闷的是，你设置的sqlSessionFactoryBeanName根本没有用。这来自于内部，自以为是的externalSqlSession变量。当此变量为true时，setSqlSessionFactory方法会直接返回。因为，setSqlSessionTemplate会比属性注入的applyPropertyValues更先运行，这一切是不是很让人郁闷。 所以在xml中配置文件改成12345678&lt;bean id=\"oracleSqlSession\" class=\"org.mybatis.spring.SqlSessionTemplate\"&gt; &lt;constructor-arg index=\"0\" ref=\"oracleSqlSessionFactory\" /&gt;&lt;/bean&gt;&lt;bean id=\"oracleMapperScannerConfigurer\" class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"com.xxx.oracle\" /&gt; &lt;!-- 由于spring-mybatis的问题，不能使用sqlSessionFactoryBeanName --&gt; &lt;property name=\"sqlSessionTemplateBeanName\" value=\"oracleSqlSession\" /&gt;&lt;/bean&gt; 问题解决了！！！","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.badwolfbay.cn/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.badwolfbay.cn/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://www.badwolfbay.cn/tags/Spring/"},{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.badwolfbay.cn/tags/Mybatis/"}]},{"title":"Aria2+YAAW+Tampermonkey下载百度云文件","slug":"aria2-yaaw","date":"2018-01-04T03:10:00.000Z","updated":"2018-01-04T03:13:22.000Z","comments":true,"path":"2018/01/04/aria2-yaaw/","link":"","permalink":"http://www.badwolfbay.cn/2018/01/04/aria2-yaaw/","excerpt":"","text":"BaiduExporter插件被Google下架，安装BaiduExporter插件只能离线安装，但是会提示只能通过Chrome网上应用商店安装该程序的错误(可以通过加压后再进行安装)，如果不想安装这个插件，可以安装YAAW。 因为公司换了电脑，不再使用Mac，重新在Win7上安装Aria2。 下载安装aria21.进入官网下载页面Aria22.下载win版本的压缩包3.解压后放到一个目录下，如：D:\\Aria2,然后在这个目录下建立3个文件，分别为 Aria2.log(日志，空文件) aria2.session(日志，空文件) aria2.conf(配置文件) 配置aria2打开aria2.conf文件，将一下内容复制到文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101dir=D:\\Download\\log=D:\\Aria2\\Aria2.loginput-file=D:\\Aria2\\aria2.sessionsave-session=D:\\Aria2\\aria2.sessionsave-session-interval=60force-save=truelog-level=error# see --split optionmax-concurrent-downloads=5continue=truemax-overall-download-limit=0max-overall-upload-limit=50Kmax-upload-limit=20# Http/FTP optionsconnect-timeout=120lowest-speed-limit=10Kmax-connection-per-server=10max-file-not-found=2min-split-size=1Msplit=5check-certificate=falsehttp-no-cache=true# FTP Specific Options# BT/PT Settingbt-enable-lpd=true#bt-max-peers=55follow-torrent=trueenable-dht6=falsebt-seed-unverifiedrpc-save-upload-metadata=truebt-hash-check-seedbt-remove-unselected-filebt-request-peer-speed-limit=100Kseed-ratio=0.0# Metalink Specific Options# RPC Optionsenable-rpc=truepause=falserpc-allow-origin-all=truerpc-listen-all=truerpc-save-upload-metadata=truerpc-secure=false# Advanced Optionsdaemon=truedisable-ipv6=trueenable-mmap=truefile-allocation=falloc max-download-result=120#no-file-allocation-limit=32Mforce-sequential=trueparameterized-uri=true 注意修改以下几项 dir=D:\\Download\\ log=D:\\Aria2\\Aria2.log input-file=D:\\Aria2\\aria2.session save-session=D:\\Aria2\\aria2.session 在cmd中启动:aria2c.exe --conf-path=aria2.conf 安装YAAW插件在chrome的插件商店搜索YAAW找到YAAW for Chrome进行安装 然后在所有的下载链接上右键选择ARIA2 RPC进行下载就可以了。 Aria2 Web1.可以直接现在访问http://aria2c.com2.点击chrome插件yaaw，也可以直接看到下载任务 百度云大文件链接 安装油猴插件（插件商店搜索Tampermonkey并安装） 安装EX-百度云盘油猴脚本(EX-百度云盘) 百度云盘中的页面中会多一个EX-下载的选项 这时在EX-下载的下拉菜单中的普通下载右键还不能将任务发送aria2进行下载，需要将文件共享。 在共享页面的EX-下载的菜单中选择普通下载后，Chrome就可以下载大文件了。然后在下载的链接上右击，选择ARIA2-RPC就可以了。 按照上边的Aria2 Web可以查看下载的文件和进度。 TODOaria2的启动时在cmd中启动的，需要使用脚本启动并隐藏cmd窗口。","categories":[{"name":"软件","slug":"软件","permalink":"http://www.badwolfbay.cn/categories/软件/"}],"tags":[{"name":"Baidu","slug":"Baidu","permalink":"http://www.badwolfbay.cn/tags/Baidu/"}]},{"title":"利用Django Admin管理","slug":"django-admin","date":"2017-12-29T06:38:01.000Z","updated":"2018-01-04T03:17:24.000Z","comments":true,"path":"2017/12/29/django-admin/","link":"","permalink":"http://www.badwolfbay.cn/2017/12/29/django-admin/","excerpt":"","text":"Python的Web框架Django有一个很厉害的功能就是可以根据数据的表结构生成models,然后利用自带的admin管理界面进行管理。 安装(Windows)1.安装Python 下载地址: https://www.python.org/getit注:安装时选择安装pip 2.配置环境 在Windows的环境变量中path中添加C:\\Python\\Python36-32;C:\\Python\\Python36-32\\Scripts 3.安装Django 在cmd中执行1pip install Django==2.0 配置Django根据数据库反向生成model 1.新建项目 在想要存储的目录下执行命令 1django-admin startproject cwtb 2.修改数据库修改新建项目的settings.py文件数据库连接 12345678910DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &apos;fms_cwtb&apos;, &apos;USER&apos;: &apos;jxq&apos;, &apos;PASSWORD&apos;: &apos;jxq&apos;, &apos;HOST&apos;: &apos;192.168.157.61&apos;, &apos;PORT&apos;: &apos;3306&apos;, &#125;&#125; 3.执行命令 1234#安装MySQL客户端pip install mysqlclient#生成modelspython manage.py inspectdb 4.创建app，导入models 123python manage.py startapp apppython manage.py inspectdb &gt; app/models.py 5.生成admin需要的表到数据库 12python manage.py migrate authpython manage.py migrate 6.创建登录用户名密码 1python manage.py createsuperuser 期间会要求输入用户名/密码:admin/admin1234 7.admin中注册app 修改admin.py 123456789from django.contrib import adminfrom app.models import FmsTbBiTs# Register your models here.@admin.register(FmsTbBiTs)class FmsTbCpkDjcAdmin(admin.ModelAdmin): list_display = (&apos;id&apos;, &apos;year&apos;, &apos;quarter&apos;, &apos;month&apos;, &apos;dept_code&apos;, &apos;dept_name&apos;, &apos;project_code&apos;, &apos;project_name&apos;,&apos;km_code&apos;, &apos;km_name&apos;, &apos;tsz&apos;, &apos;data_type&apos;, &apos;tb_type&apos;, &apos;bz1&apos;, &apos;bz2&apos;, &apos;bz3&apos;, &apos;bz4&apos;, &apos;create_time&apos;, &apos;update_time&apos;) 8.修改setting.py,将新建的app应用添加到INSTALLED_APPS 12345678910INSTALLED_APPS = [ &apos;django.contrib.admin&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;, &apos;app&apos;] 9.修改中英文配置 修改settings.py文件 123LANGUAGE_CODE = &apos;zh-hans&apos;TIME_ZONE = &apos;Asia/Shanghai&apos; 10.启动Admin管理后台 1python manage.py runserver 0.0.0.0:8000 访问 http://localhost:8000/admin会看到登陆界面","categories":[{"name":"python","slug":"python","permalink":"http://www.badwolfbay.cn/categories/python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.badwolfbay.cn/tags/Python/"}]},{"title":"百度云盘大文件下载及wget命令下载","slug":"wget-baidu-yunpan","date":"2017-12-11T02:12:53.000Z","updated":"2017-12-11T06:28:42.000Z","comments":true,"path":"2017/12/11/wget-baidu-yunpan/","link":"","permalink":"http://www.badwolfbay.cn/2017/12/11/wget-baidu-yunpan/","excerpt":"大文件下载 (chrome)1.安装Tampermonkey 下载Tampermonkeyctx安装文件,拖拽到chrome扩展程序进行安装 2.安装脚本 https://greasyfork.org/zh-CN 搜索 百度云，找到解决百度云大文件下载限制，点击安装脚本 点击下载即可在chrome中下载大文件 wget命令下载在不使用客户端的情况下，在Linux上可以使用wget命令下载文件 1wget -c --referer=&quot;https://pan.baidu.com/s/1geShrcn&quot; -O USB_Clover_El_10.11.2_15C50.dmg &quot;https://d11.baidupcs.com/file/4fe11b6499aadfb6d6c71a069347b2ef?bkt=p3-000041b61dfd29c78e715750f5f368b68f21&amp;xcode=8b170a5746c3e069110d88ded6ecebe0753c975f9b99f324&amp;fid=2634882875-250528-446076603732633&amp;time=1512955781&amp;sign=FDTAXGERLQBHSK-DCb740ccc5511e5e8fedcff06b081203-DhXO3o2T%2FM61XgCfTOIdJdBKfIs%3D&amp;to=d11&amp;size=6331828199&amp;sta_dx=6331828199&amp;sta_cs=1408&amp;sta_ft=dmg&amp;sta_ct=7&amp;sta_mt=0&amp;fm2=MH,Yangquan,Anywhere,,guangdong,ct&amp;vuk=2634882875&amp;iv=0&amp;newver=1&amp;newfm=1&amp;secfm=1&amp;flow_ver=3&amp;pkey=000041b61dfd29c78e715750f5f368b68f21&amp;sl=83034191&amp;expires=8h&amp;rt=sh&amp;r=740312867&amp;mlogid=7987506833960085243&amp;vbdid=502990198&amp;fin=USB_Clover_El_10.11.2_15C50.dmg&amp;fn=USB_Clover_El_10.11.2_15C50.dmg&amp;rtype=1&amp;dp-logid=7987506833960085243&amp;dp-callid=0.1.1&amp;hps=1&amp;tsl=300&amp;csl=300&amp;csign=7qu6lUTZwacrMJY1n%2Fm13tTPRpA%3D&amp;so=0&amp;ut=6&amp;uter=4&amp;serv=0&amp;uc=1539727773&amp;ic=815197955&amp;ti=91499ea5817d8028239ebf7886cf11f2e88e8e5223093275&amp;by=themis&quot; --referer后为分享链接(自己的文件可以先创建一个分享链接)，-O为下载后的文件名后边为chrome下载时的文件真实地址,文件上右击复制链接地址即可","text":"大文件下载 (chrome)1.安装Tampermonkey 下载Tampermonkeyctx安装文件,拖拽到chrome扩展程序进行安装 2.安装脚本 https://greasyfork.org/zh-CN 搜索 百度云，找到解决百度云大文件下载限制，点击安装脚本 点击下载即可在chrome中下载大文件 wget命令下载在不使用客户端的情况下，在Linux上可以使用wget命令下载文件 1wget -c --referer=&quot;https://pan.baidu.com/s/1geShrcn&quot; -O USB_Clover_El_10.11.2_15C50.dmg &quot;https://d11.baidupcs.com/file/4fe11b6499aadfb6d6c71a069347b2ef?bkt=p3-000041b61dfd29c78e715750f5f368b68f21&amp;xcode=8b170a5746c3e069110d88ded6ecebe0753c975f9b99f324&amp;fid=2634882875-250528-446076603732633&amp;time=1512955781&amp;sign=FDTAXGERLQBHSK-DCb740ccc5511e5e8fedcff06b081203-DhXO3o2T%2FM61XgCfTOIdJdBKfIs%3D&amp;to=d11&amp;size=6331828199&amp;sta_dx=6331828199&amp;sta_cs=1408&amp;sta_ft=dmg&amp;sta_ct=7&amp;sta_mt=0&amp;fm2=MH,Yangquan,Anywhere,,guangdong,ct&amp;vuk=2634882875&amp;iv=0&amp;newver=1&amp;newfm=1&amp;secfm=1&amp;flow_ver=3&amp;pkey=000041b61dfd29c78e715750f5f368b68f21&amp;sl=83034191&amp;expires=8h&amp;rt=sh&amp;r=740312867&amp;mlogid=7987506833960085243&amp;vbdid=502990198&amp;fin=USB_Clover_El_10.11.2_15C50.dmg&amp;fn=USB_Clover_El_10.11.2_15C50.dmg&amp;rtype=1&amp;dp-logid=7987506833960085243&amp;dp-callid=0.1.1&amp;hps=1&amp;tsl=300&amp;csl=300&amp;csign=7qu6lUTZwacrMJY1n%2Fm13tTPRpA%3D&amp;so=0&amp;ut=6&amp;uter=4&amp;serv=0&amp;uc=1539727773&amp;ic=815197955&amp;ti=91499ea5817d8028239ebf7886cf11f2e88e8e5223093275&amp;by=themis&quot; --referer后为分享链接(自己的文件可以先创建一个分享链接)，-O为下载后的文件名后边为chrome下载时的文件真实地址,文件上右击复制链接地址即可 安装aria2Mac下安装aria2 brew install aria2 github地址 aria2 如果使用命令行下载不需要启动以下的RPC服务启动aria2的RPC服务，创建aria2.conf文件在/usr/local/Cellar/aria2/1.33.1/etc目录下，可以创建在任意目录，执行 1aria2c --conf-path=/usr/local/Cellar/aria2/1.33.1/etc/aria2.conf -D aria2.conf文件内容如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#用户名#rpc-user=user#密码#rpc-passwd=passwd#上面的认证方式不建议使用,建议使用下面的token方式#设置加密的密钥#rpc-secret=token#允许rpcenable-rpc=true#允许所有来源, web界面跨域权限需要rpc-allow-origin-all=true#允许外部访问，false的话只监听本地端口rpc-listen-all=true#RPC端口, 仅当默认端口被占用时修改#rpc-listen-port=6800#最大同时下载数(任务数), 路由建议值: 3max-concurrent-downloads=5#断点续传continue=true#同服务器连接数max-connection-per-server=5#最小文件分片大小, 下载线程数上限取决于能分出多少片, 对于小文件重要min-split-size=10M#单文件最大线程数, 路由建议值: 5split=10#下载速度限制max-overall-download-limit=0#单文件速度限制max-download-limit=0#上传速度限制max-overall-upload-limit=0#单文件速度限制max-upload-limit=0#断开速度过慢的连接#lowest-speed-limit=0#验证用，需要1.16.1之后的release版本#referer=*#文件保存路径, 默认为当前启动位置dir=/Users/badwolf/Downloads#文件缓存, 使用内置的文件缓存, 如果你不相信Linux内核文件缓存和磁盘内置缓存时使用, 需要1.16及以上版本#disk-cache=0#另一种Linux文件缓存方式, 使用前确保您使用的内核支持此选项, 需要1.15及以上版本(?)#enable-mmap=true#文件预分配, 能有效降低文件碎片, 提高磁盘性能. 缺点是预分配时间较长#所需时间 none &lt; falloc ? trunc &lt;&lt; prealloc, falloc和trunc需要文件系统和内核支持file-allocation=prealloc 安装百度云aria2插件 https://github.com/acgotaku/BaiduExporter 下载ctx文件，安装后可能会出现只能通过Chrome网上应用商店安装该程序的错误需要将文件解压后用开发者模式加载已解压的扩展程序方式安装PS:插件安装位置C:\\Users\\xxxx\\AppData\\Local\\Google\\Chrome\\User Data\\Default\\Extensions 安装后重新打开百度云即可以看到导出下载有ARIA2的相关配置,如果没有，需要在F12控制台下多刷新几次直到提示初始化成功为止 因为我是远程下载点击文本导出，复制aria2c的命令执行即可。","categories":[],"tags":[]},{"title":"Java多线程synchronized","slug":"java-synchronized","date":"2017-12-06T02:08:20.000Z","updated":"2017-12-06T02:11:42.000Z","comments":true,"path":"2017/12/06/java-synchronized/","link":"","permalink":"http://www.badwolfbay.cn/2017/12/06/java-synchronized/","excerpt":"","text":"synchronized依靠锁机制实现多线程的同步，锁分两种 对象锁 类锁 1.synchronized作用于普通方法时依靠对象锁工作，多线程访问synchronized方法，一旦某个线程抢到锁后，其他进程排队等待等效于1234void method&#123; synchronized(this)&#123; &#125;&#125; 示例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class TestSynchronized &#123; public synchronized void method1() throws InterruptedException &#123; System.out.println(&quot;Method1 start at :&quot; + System.currentTimeMillis()); Thread.sleep(6000); System.out.println(&quot;Method1 end at :&quot; + System.currentTimeMillis()); &#125; public synchronized void method2() throws InterruptedException &#123; while (true) &#123; System.out.println(&quot;method2 running&quot;); Thread.sleep(200); &#125; &#125; static TestSynchronized instance = new TestSynchronized(); public static void main(String[] args) &#123; Thread thread1 = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; instance.method1(); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; for (int i = 1; i &lt; 4; i++) &#123; try &#123; Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;Thread1 still alive&quot;); &#125; &#125; &#125;); Thread thread2 = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; instance.method2(); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;); thread1.start(); thread2.start(); &#125;&#125; 方法method2会一直等待method1执行完成后再执行。synchronized void method(){}整个函数加上synchronized块，效率并不好。 2.synchronized作用于静态方法相当于 1234void method()&#123; synchronized(Object.class)&#123; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://www.badwolfbay.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.badwolfbay.cn/tags/Java/"}]},{"title":"JVM学习一","slug":"jvm-study-1","date":"2017-11-15T13:22:11.000Z","updated":"2017-11-16T02:26:39.000Z","comments":true,"path":"2017/11/15/jvm-study-1/","link":"","permalink":"http://www.badwolfbay.cn/2017/11/15/jvm-study-1/","excerpt":"OutOfMemoryError异常 JAVA堆溢出Java堆用来存储对象实例，只要不断的创建对象，只要在对象数量达到最大堆的容量限制后就会产生内存溢出 通过设置堆的最小值(-Xms)参数和最大值(-Xmx)设置相等来避免堆自动扩展 12345678910111213// VM args -Xmx20m -Xms20mpublic class HeapOOM &#123; static class OOMObject&#123; &#125; public static void main(String[] args)&#123; List&lt;OOMObject&gt; list = new ArrayList&lt;&gt;(); while(true)&#123; list.add(new OOMObject()); &#125; &#125;&#125; 报错信息 1Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space 虚拟机栈和本地方法溢出在HotSpot虚拟机中并不区分虚拟机栈和本地方法栈栈容量只能通过-Xss来设置存放基本数据类型(byte,char,boolean,shot,int,long,float,double)和对象的引用类型 1234567891011121314151617181920// VM args -Xss128kpublic class JavaVMStackSOF &#123; private int stackLength = -1; public void stackLeak()&#123; stackLength++; stackLeak(); &#125; public static void main(String[] args)&#123; JavaVMStackSOF oom = new JavaVMStackSOF(); try&#123; oom.stackLeak(); &#125;catch(Throwable e)&#123; System.out.println(&quot;stack length:&quot; + oom.stackLength); throw e; &#125; &#125;&#125;","text":"OutOfMemoryError异常 JAVA堆溢出Java堆用来存储对象实例，只要不断的创建对象，只要在对象数量达到最大堆的容量限制后就会产生内存溢出 通过设置堆的最小值(-Xms)参数和最大值(-Xmx)设置相等来避免堆自动扩展 12345678910111213// VM args -Xmx20m -Xms20mpublic class HeapOOM &#123; static class OOMObject&#123; &#125; public static void main(String[] args)&#123; List&lt;OOMObject&gt; list = new ArrayList&lt;&gt;(); while(true)&#123; list.add(new OOMObject()); &#125; &#125;&#125; 报错信息 1Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space 虚拟机栈和本地方法溢出在HotSpot虚拟机中并不区分虚拟机栈和本地方法栈栈容量只能通过-Xss来设置存放基本数据类型(byte,char,boolean,shot,int,long,float,double)和对象的引用类型 1234567891011121314151617181920// VM args -Xss128kpublic class JavaVMStackSOF &#123; private int stackLength = -1; public void stackLeak()&#123; stackLength++; stackLeak(); &#125; public static void main(String[] args)&#123; JavaVMStackSOF oom = new JavaVMStackSOF(); try&#123; oom.stackLeak(); &#125;catch(Throwable e)&#123; System.out.println(&quot;stack length:&quot; + oom.stackLength); throw e; &#125; &#125;&#125; 方法区和运行时常量溢出JDK1.6以及之前的版本中，常量池分配在”永久代”中,JDK1.7以后开始“去永久代”通过-XX:PermSize和-XX:MaxPermSize限制方法区大小String.intern()是一个Native方法，在JDK1.6之前，intern()方法会将首次遇到的字符串实例复制到”永久代”中，返回的也是”永久代”中的实例，JDK1.7以后不会再复制实例123456789public class RuntimeConstantPoolOOM &#123; public static void main(String[] args) &#123; String str1 = new StringBuilder(&quot;计算机&quot;).append(&quot;软件&quot;).toString(); System.out.println(str1.intern() == str1); String str2 = new StringBuilder(&quot;ja&quot;).append(&quot;va&quot;).toString(); System.out.println(str2.intern() == str2); &#125;&#125; 所以在JDK1.6和JDK1.7上执行上边的代码会出现不同的结果；JDK1.6中会是两个false,JDK1.7上会是一个true，一个false 本机直接内存溢出","categories":[{"name":"Java","slug":"Java","permalink":"http://www.badwolfbay.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.badwolfbay.cn/tags/Java/"}]},{"title":"HashMap总结","slug":"java-hashmap","date":"2017-11-15T13:21:37.000Z","updated":"2017-11-16T02:28:10.000Z","comments":true,"path":"2017/11/15/java-hashmap/","link":"","permalink":"http://www.badwolfbay.cn/2017/11/15/java-hashmap/","excerpt":"","text":"基于Map接口实现，允许null键/值，非同步(线程不安全)，不保证有序，也不保证顺序不随时间变化；存储着Entry（hash,key,value,next）对象 两个重要参数容量(Capacity)和负载因子(Load factor) HashMap在new后并不会分配数组，而是在第一次put时进行初始化，类似ArrayList在第一次add时分配内存空间 HashMap的bucket数组大小一定是2的幂，如果是new的时候指定了容量且不是2的幂，实际容量会是最接近且大于指定容量的2的幂，如new HashMap&lt;&gt;(19)，实际容量为32 HashMap在put的元素大于Capacity*LoadFactor(默认16*0.75)之后会进行扩容 JDK8处于提升性能的考虑，在哈希碰撞的链表长度达到TREEIFY_THRESHOLD(默认8)后，会把该链表转变成树结构 JDK8在resize的时候，通过巧妙的设计，减少了rehash的性能消耗;resize是扩容的两倍 http://yikun.github.io","categories":[{"name":"Java","slug":"Java","permalink":"http://www.badwolfbay.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.badwolfbay.cn/tags/Java/"}]},{"title":"Go指南学习笔记十三","slug":"go-tour-note-13","date":"2017-11-08T05:46:20.000Z","updated":"2017-11-08T06:40:47.000Z","comments":true,"path":"2017/11/08/go-tour-note-13/","link":"","permalink":"http://www.badwolfbay.cn/2017/11/08/go-tour-note-13/","excerpt":"range和close发送者可以通过close来关闭channel。接受者可以通过传入第二个参数来测试channl是否被关闭 1v, ok := &lt;-ch 循环for i := range c会不断从channl接受值，直到它被关闭。 只有发送者能关闭channel,而不是接收者 1234567891011121314151617181920212223package mainimport ( &quot;fmt&quot;)//斐波那契数列func fibonacci(n int, c chan int) &#123; x, y := 0, 1 for i := 0; i &lt; n; i++ &#123; c &lt;- x x, y = y, x+y &#125; close(c)&#125;func main()&#123; c := make(chan int, 10) go fibonacci(cap(c), c) for i := range c &#123; fmt.Println(i) &#125;&#125; 输出结果 123456789100112358132134","text":"range和close发送者可以通过close来关闭channel。接受者可以通过传入第二个参数来测试channl是否被关闭 1v, ok := &lt;-ch 循环for i := range c会不断从channl接受值，直到它被关闭。 只有发送者能关闭channel,而不是接收者 1234567891011121314151617181920212223package mainimport ( &quot;fmt&quot;)//斐波那契数列func fibonacci(n int, c chan int) &#123; x, y := 0, 1 for i := 0; i &lt; n; i++ &#123; c &lt;- x x, y = y, x+y &#125; close(c)&#125;func main()&#123; c := make(chan int, 10) go fibonacci(cap(c), c) for i := range c &#123; fmt.Println(i) &#125;&#125; 输出结果 123456789100112358132134 selectselect使得一个goroutine在多个通讯操作中等待。 select会阻塞，直到条件分支中的某个可以继续执行，这时就会执行那个分支。当多个都准备好时，会随机选择一个。 12345678910111213141516171819202122232425262728package mainimport &quot;fmt&quot;func fibonacci(c, quit chan int) &#123; x, y := 0, 1 for &#123; select &#123; case c &lt;- x: x, y = y, x+y case &lt;-quit: fmt.Println(&quot;quit&quot;) return &#125; &#125;&#125;func main()&#123; c := make(chan int) quit := make(chan int) go func()&#123; for i := 0; i &lt; 10; i++ &#123; fmt.Println(&lt;-c) &#125; quit &lt;- 0 &#125;() fibonacci(c, quit)&#125; 输出结果12345678910110112358132134quit 默认选择当select中的其他分支都没有准备好的时候，default分支会被执行。为了非阻塞的发送或者接口，可以使用default分支。 123456789101112131415161718192021222324package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main() &#123; tick := time.Tick(100 * time.Millisecond) boom := time.After(500 * time.Millisecond) for &#123; select &#123; case &lt;-tick: fmt.Println(&quot;tick.&quot;) case &lt;-boom: fmt.Println(&quot;BOOM!&quot;) return default: fmt.Println(&quot; .&quot;) time.Sleep(50 * time.Microsecond) &#125; &#125;&#125; sync.Mutex如果只想保证每个时刻，只有一个goroutine能访问一个共享的变量避免冲突怎么办？这里涉及的概念叫做互斥，使用互斥锁mutex来提供这个限制。Go标准库中提供了sync.Mutex类型以及两个方法 Lock Unlock 12345678910111213141516171819202122232425262728293031323334353637package mainimport ( &quot;fmt&quot; &quot;time&quot; &quot;sync&quot;)//并发是安全的type SafeCounter struct&#123; v map[string] int mux sync.Mutex&#125;func (c *SafeCounter) Inc(key string) &#123; c.mux.Lock() //lock之后同一时刻只有一个goroutine能访问c.v c.v[key]++ c.mux.Unlock()&#125;// Value 返回给定 key 的计数器的当前值。func (c *SafeCounter) Value(key string) int &#123; c.mux.Lock() // Lock 之后同一时刻只有一个 goroutine 能访问 c.v defer c.mux.Unlock() return c.v[key]&#125;func main() &#123; c := SafeCounter&#123;v: make(map[string] int)&#125; for i := 0; i &lt; 1000; i++ &#123; go c.Inc(&quot;somekey&quot;) &#125; time.Sleep(time.Second) fmt.Println(c.Value(&quot;somekey&quot;))&#125; 输出结果11000","categories":[{"name":"golang","slug":"golang","permalink":"http://www.badwolfbay.cn/categories/golang/"}],"tags":[{"name":"go","slug":"go","permalink":"http://www.badwolfbay.cn/tags/go/"}]},{"title":"Go指南学习笔记十二","slug":"go-tour-note-12","date":"2017-11-07T01:50:29.000Z","updated":"2017-11-07T02:40:38.000Z","comments":true,"path":"2017/11/07/go-tour-note-12/","link":"","permalink":"http://www.badwolfbay.cn/2017/11/07/go-tour-note-12/","excerpt":"goroutinegoroutine是Go运行时环境管理的轻量级线程 go f(x,y,z) 开启一个新的goroutine执行。 f,x,y,z是在当前goroutine中定义的，但是在新的goroutine中运行f。 goroutine在相同的地址空间中运行，因此访问共享内存必须同步。sync提供了这种可能，不过在Go中并不经常用到，因为还有其他办法。 123456789101112131415161718package mainimport ( &quot;fmt&quot; &quot;time&quot;)func say(s string) &#123; for i:=0; i&lt;5; i++ &#123; time.Sleep(100 * time.Millisecond) fmt.Println(s) &#125;&#125;func main() &#123; go say(&quot;world&quot;) say(&quot;hello&quot;)&#125; 运行结果,hello和world交替运行。 1234567891011[Running] go run &quot;f:\\study\\go\\smp\\src\\goroutine.go&quot;worldhellohelloworldhelloworldhelloworldworldhello","text":"goroutinegoroutine是Go运行时环境管理的轻量级线程 go f(x,y,z) 开启一个新的goroutine执行。 f,x,y,z是在当前goroutine中定义的，但是在新的goroutine中运行f。 goroutine在相同的地址空间中运行，因此访问共享内存必须同步。sync提供了这种可能，不过在Go中并不经常用到，因为还有其他办法。 123456789101112131415161718package mainimport ( &quot;fmt&quot; &quot;time&quot;)func say(s string) &#123; for i:=0; i&lt;5; i++ &#123; time.Sleep(100 * time.Millisecond) fmt.Println(s) &#125;&#125;func main() &#123; go say(&quot;world&quot;) say(&quot;hello&quot;)&#125; 运行结果,hello和world交替运行。 1234567891011[Running] go run &quot;f:\\study\\go\\smp\\src\\goroutine.go&quot;worldhellohelloworldhelloworldhelloworldworldhello channelchannel是有类型的管道，可以使用channel操作符&lt;-对齐发送或者接受值 12ch &lt;- v //将v送给channel chv := &lt;-ch //从ch接收，并且赋值给v 和map与slice一样，使用前必须创建 1ch := make(chan int) 默认情况下，在另一端准备好之前，发送和接受都会阻塞。这使得goroutine可以在没有明确的锁或竞态变量的情况下进行同步。 123456789101112131415161718192021222324package mainimport ( &quot;fmt&quot;)func sum(a []int, c chan int) &#123; sum := 0 for _, v := range a &#123; sum += v &#125; c &lt;- sum // 将sum送入c&#125;func main() &#123; a := []int&#123;7, 2, 8, -9, 4, 0&#125; c := make(chan int) go sum(a[:len(a)/2], c) go sum(a[len(a)/2:], c) x, y := &lt;-c, &lt;-c fmt.Println(x, y , x+y)&#125; 输出结果 1-5 17 12 或者 17 -5 12 缓冲channelchannel是可以带缓冲的。为make提供第二个参数作为缓冲长度来初始化一个缓冲channel 1ch := make(chan int, 100) 向带缓冲的channel发送数据时，只有在缓冲区慢的时候才会发生阻塞。而当缓冲区为空时接受操作会阻塞。 12345678910111213package mainimport ( &quot;fmt&quot;)func main() &#123; ch := make(chan int, 2) ch &lt;- 1 ch &lt;- 2 fmt.Println(&lt;-ch) fmt.Println(&lt;-ch)&#125; 输出结果1212","categories":[{"name":"golang","slug":"golang","permalink":"http://www.badwolfbay.cn/categories/golang/"}],"tags":[{"name":"go","slug":"go","permalink":"http://www.badwolfbay.cn/tags/go/"}]},{"title":"百度Java面试题汇总","slug":"java-interview","date":"2017-10-26T11:57:27.000Z","updated":"2017-11-06T05:13:53.000Z","comments":true,"path":"2017/10/26/java-interview/","link":"","permalink":"http://www.badwolfbay.cn/2017/10/26/java-interview/","excerpt":"","text":"简单记录下百度Java面试题 Java源码使用了哪些设计模式？列举你知道的类/包以及使用模式 写一个单例模式 Threadlocal有哪些特点，描述使用场景 快速排序 Mysql事务隔离级别(Spring事务隔离级别) 字符串常量池 类加载器 SpringMVC和Struts2有什么区别？(需要跟进新技术，为什么SpringMVC替代Struts2) Java，Python和Go三个相比各自有什么优点和缺点(需要自己总结思考) 网络传输,应用层有哪些协议?(并问了Http头的详细信息) 设计一个互联网架构 接上：当访问量多比如秒杀可能的瓶颈在哪里,怎么解决这些瓶颈问题 数据库怎么读写分离，怎么分库分表 Java中HashMap的containsKey和containsValue的时间复杂度 线程池的最大线程数和核心线程数 Spring事务的处理及回滚机制（事务的一致性） JAVA的装饰者模式和IO流 Mybatis插入的返回值 Synchrosized的静态方法和普通方法上的区别 时间复杂度/空间复杂度 需要自己接下来深入学习JVM，网络层。由底层原理–&gt;架构–&gt;项目/应用/数据/性能","categories":[{"name":"Java","slug":"Java","permalink":"http://www.badwolfbay.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.badwolfbay.cn/tags/Java/"}]},{"title":"Go指南学习笔记十一","slug":"go-tour-note-11","date":"2017-10-25T01:10:40.000Z","updated":"2017-10-25T01:52:40.000Z","comments":true,"path":"2017/10/25/go-tour-note-11/","link":"","permalink":"http://www.badwolfbay.cn/2017/10/25/go-tour-note-11/","excerpt":"错误Go使用error来标识错误状态。同fmt.Stringer一样，error类型也是个内建接口。 123type error interface &#123; Error() string&#125; 通常函数会返回一个error值，调用它的代码应判断这个错误是否等于nil来进行错误处理。 1234567i, err := strconv.Atoi(&quot;42&quot;)if err ！= nil &#123; fmt.Printf(&quot;conldn&apos;t convert number: %v\\n&quot;, err) return&#125;fmt.Printfln(&quot;Converted integer:&quot;, i) error为nil时表示成功；非nil的error表示错误","text":"错误Go使用error来标识错误状态。同fmt.Stringer一样，error类型也是个内建接口。 123type error interface &#123; Error() string&#125; 通常函数会返回一个error值，调用它的代码应判断这个错误是否等于nil来进行错误处理。 1234567i, err := strconv.Atoi(&quot;42&quot;)if err ！= nil &#123; fmt.Printf(&quot;conldn&apos;t convert number: %v\\n&quot;, err) return&#125;fmt.Printfln(&quot;Converted integer:&quot;, i) error为nil时表示成功；非nil的error表示错误 如：12345678910111213141516171819202122232425package mainimport ( &quot;fmt&quot; &quot;time&quot;)type MyError struct &#123; When time.Time What string&#125;func (e *MyError) Error() string &#123; return fmt.Sprintf(&quot;at %v, %s&quot;, e.When, e.What)&#125;func run() error &#123; return &amp;MyError&#123;time.Now(), &quot;it didn&apos;t work&quot;,&#125;&#125;func main() &#123; if err := run(); err != nil &#123; fmt.Println(err) // &#125;&#125; 运行输出结果：1at 2017-10-25 09:31:30.9208855 +0800 CST, it didn&apos;t work","categories":[{"name":"golang","slug":"golang","permalink":"http://www.badwolfbay.cn/categories/golang/"}],"tags":[{"name":"go","slug":"go","permalink":"http://www.badwolfbay.cn/tags/go/"}]},{"title":"非root用户运行docker","slug":"not-root-run-docker","date":"2017-10-13T01:31:04.000Z","updated":"2017-10-13T01:45:51.000Z","comments":true,"path":"2017/10/13/not-root-run-docker/","link":"","permalink":"http://www.badwolfbay.cn/2017/10/13/not-root-run-docker/","excerpt":"","text":"转载： 原文出处： https://notes.wanghao.work/2017-07-11-Docker非Root用户运行.html Docker Engine的Deamon进程是以root权限运行的，如果是普通用户要与之交互，需要使用sudo命令来提权与之交互。之前使用Docker官方的安装脚本安装完成之后，会给出一个提示将当前非root用户添加到doker组之中，以避免每次都需要输入sudo的麻烦。 然而随着Docker版本的迭代和官网的安装方式的更改，现在官方给出的安装方式是添加仓库源地址，然后使用默认的apt或者yum包管理工具来完成后安装。并不再提示用户添加非root用户到组。 默认情况下，完成Docker Engine的安装之后，Docker将会自动创建一个名为docker的用户组，所以root用户和在docker组中的用户都可以免去sudo来与Docker Engine交互。知道原理之后就简单了： 1sudo usermod -aG docker $&#123;whoami&#125; #添加当前用户到docker组","categories":[{"name":"docker","slug":"docker","permalink":"http://www.badwolfbay.cn/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.badwolfbay.cn/tags/docker/"}]},{"title":"Go指南学习笔记十","slug":"go-tour-note-10","date":"2017-10-12T13:15:45.000Z","updated":"2017-10-12T13:47:07.000Z","comments":true,"path":"2017/10/12/go-tour-note-10/","link":"","permalink":"http://www.badwolfbay.cn/2017/10/12/go-tour-note-10/","excerpt":"","text":"Stringers普遍存在的接口是fmt包中定义的Stringer 123type Stringer inferface &#123; String() string&#125; Stringer是一个可以用字符串描述自己的类型。 12345678910111213141516171819package mainimport ( &quot;fmt&quot;)type Person struct &#123; Name string Age int&#125;func (p Person) String() string &#123; return fmt.Sprintf(&quot;%v (%v years)&quot;, p.Name, p.Age)&#125;func main() &#123; a := Person&#123;&quot;Dent&quot;, 42&#125; z := Person&#123;&quot;Foo&quot;, 90&#125; fmt.Println(a, z) // 输出Dent (42 years) Foo (90 years)&#125;","categories":[{"name":"golang","slug":"golang","permalink":"http://www.badwolfbay.cn/categories/golang/"}],"tags":[{"name":"go","slug":"go","permalink":"http://www.badwolfbay.cn/tags/go/"}]},{"title":"Kubernetes网络组件Calico安装","slug":"calico-install-on-kubernetes","date":"2017-09-26T06:43:51.000Z","updated":"2017-09-27T03:11:43.000Z","comments":true,"path":"2017/09/26/calico-install-on-kubernetes/","link":"","permalink":"http://www.badwolfbay.cn/2017/09/26/calico-install-on-kubernetes/","excerpt":"参照官网地址: https://docs.projectcalico.org/v2.5/getting-started/kubernetes/installation/integration Calico组件包括 calico/node， 必须安装在Master节点和每个计算节点上，包括BGP agent,负责网络策略。 cni/plugin， 和kubelet交互发现pod。 calico/policy-controller ,实现kubernetes的Network Policy API. 本文中安装的calico版本为2.5,对应的组件版本分别为: calicoctl:v1.5.0cni-plugin:v1.10.0cni:v0.3.0 安装calico/node12345$ wget https://github.com/projectcalico/calicoctl/releases/download/v1.5.0/calicoctl$ sudo chmod +x calicoctl$ mv calicoctl /usr/bin 创建calico-node.service 1$ vi /usr/lib/systemd/system/calico-node.service service的内容，需要将ETCD_ENDPOINTS中地址换成真实的etcd集群地址，可以将node-image中指定所需要的镜像名称，如果不指定，默认为quay.io/calico/node:latest 下边的命令会导致calio-node一直重启，所以需要换成官网的 123456789101112131415[Unit]Description=calicoctl nodeAfter=docker.serviceRequires=docker.service[Service]User=rootEnvironment=ETCD_ENDPOINTS=http://172.21.1.201:2379PermissionsStartOnly=trueExecStart=/usr/bin/calicoctl node run --node-image=calico/node:v2.5.1Restart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 换成(替换下边的ETCD_ENDPOINTS和ExecStart命令中的镜像名称) 12345678910111213141516171819202122232425262728293031[Unit]Description=calico nodeAfter=docker.serviceRequires=docker.service[Service]User=rootEnvironment=ETCD_ENDPOINTS=http://&lt;ETCD_IP&gt;:&lt;ETCD_PORT&gt;PermissionsStartOnly=trueExecStart=/usr/bin/docker run --net=host --privileged --name=calico-node \\ -e ETCD_ENDPOINTS=$&#123;ETCD_ENDPOINTS&#125; \\ -e NODENAME=$&#123;HOSTNAME&#125; \\ -e IP= \\ -e NO_DEFAULT_POOLS= \\ -e AS= \\ -e CALICO_LIBNETWORK_ENABLED=true \\ -e IP6= \\ -e CALICO_NETWORKING_BACKEND=bird \\ -e FELIX_DEFAULTENDPOINTTOHOSTACTION=ACCEPT \\ -v /var/run/calico:/var/run/calico \\ -v /lib/modules:/lib/modules \\ -v /run/docker/plugins:/run/docker/plugins \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /var/log/calico:/var/log/calico \\ calico/node:v2.5.1ExecStop=/usr/bin/docker rm -f calico-nodeRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 启动calico-node服务 12$ systemctl daemon-reload$ systemctl start calico-node 查看服务启动情况以及容器启动情况 123456789101112$ systemctl status calico-node● calico-node.service - calicoctl node Loaded: loaded (/usr/lib/systemd/system/calico-node.service; disabled; vendor preset: disabled) Active: activating (auto-restart) since Tue 2017-09-26 09:57:00 CST; 1s ago Process: 23696 ExecStart=/usr/bin/calicoctl node run --node-image=calico/node:v2.5.1 (code=exited, status=0/SUCCESS) Main PID: 23696 (code=exited, status=0/SUCCESS) $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1cca427ef1a1 calico/node:v2.5.1 &quot;start_runit&quot; 10 seconds ago Up 9 seconds calico-node","text":"参照官网地址: https://docs.projectcalico.org/v2.5/getting-started/kubernetes/installation/integration Calico组件包括 calico/node， 必须安装在Master节点和每个计算节点上，包括BGP agent,负责网络策略。 cni/plugin， 和kubelet交互发现pod。 calico/policy-controller ,实现kubernetes的Network Policy API. 本文中安装的calico版本为2.5,对应的组件版本分别为: calicoctl:v1.5.0cni-plugin:v1.10.0cni:v0.3.0 安装calico/node12345$ wget https://github.com/projectcalico/calicoctl/releases/download/v1.5.0/calicoctl$ sudo chmod +x calicoctl$ mv calicoctl /usr/bin 创建calico-node.service 1$ vi /usr/lib/systemd/system/calico-node.service service的内容，需要将ETCD_ENDPOINTS中地址换成真实的etcd集群地址，可以将node-image中指定所需要的镜像名称，如果不指定，默认为quay.io/calico/node:latest 下边的命令会导致calio-node一直重启，所以需要换成官网的 123456789101112131415[Unit]Description=calicoctl nodeAfter=docker.serviceRequires=docker.service[Service]User=rootEnvironment=ETCD_ENDPOINTS=http://172.21.1.201:2379PermissionsStartOnly=trueExecStart=/usr/bin/calicoctl node run --node-image=calico/node:v2.5.1Restart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 换成(替换下边的ETCD_ENDPOINTS和ExecStart命令中的镜像名称) 12345678910111213141516171819202122232425262728293031[Unit]Description=calico nodeAfter=docker.serviceRequires=docker.service[Service]User=rootEnvironment=ETCD_ENDPOINTS=http://&lt;ETCD_IP&gt;:&lt;ETCD_PORT&gt;PermissionsStartOnly=trueExecStart=/usr/bin/docker run --net=host --privileged --name=calico-node \\ -e ETCD_ENDPOINTS=$&#123;ETCD_ENDPOINTS&#125; \\ -e NODENAME=$&#123;HOSTNAME&#125; \\ -e IP= \\ -e NO_DEFAULT_POOLS= \\ -e AS= \\ -e CALICO_LIBNETWORK_ENABLED=true \\ -e IP6= \\ -e CALICO_NETWORKING_BACKEND=bird \\ -e FELIX_DEFAULTENDPOINTTOHOSTACTION=ACCEPT \\ -v /var/run/calico:/var/run/calico \\ -v /lib/modules:/lib/modules \\ -v /run/docker/plugins:/run/docker/plugins \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /var/log/calico:/var/log/calico \\ calico/node:v2.5.1ExecStop=/usr/bin/docker rm -f calico-nodeRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 启动calico-node服务 12$ systemctl daemon-reload$ systemctl start calico-node 查看服务启动情况以及容器启动情况 123456789101112$ systemctl status calico-node● calico-node.service - calicoctl node Loaded: loaded (/usr/lib/systemd/system/calico-node.service; disabled; vendor preset: disabled) Active: activating (auto-restart) since Tue 2017-09-26 09:57:00 CST; 1s ago Process: 23696 ExecStart=/usr/bin/calicoctl node run --node-image=calico/node:v2.5.1 (code=exited, status=0/SUCCESS) Main PID: 23696 (code=exited, status=0/SUCCESS) $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1cca427ef1a1 calico/node:v2.5.1 &quot;start_runit&quot; 10 seconds ago Up 9 seconds calico-node 当calico-node的ExecStart配置成calicoctl run命令时会导致服务一直重启，如上表示服务未启动成功，名字为calico-node的容器会一直重启。按照如上所说的修改后，再次查看 12345678910111213141516171819$ systemctl status calico-node● calico-node.service - calicoctl node Loaded: loaded (/usr/lib/systemd/system/calico-node.service; disabled; vendor preset: disabled) Active: active (running) since Wed 2017-09-27 10:57:28 CST; 2min 4s ago Process: 21915 ExecStop=/usr/bin/docker rm -f calico-node (code=exited, status=0/SUCCESS) Main PID: 21949 (docker) Memory: 6.6M CGroup: /system.slice/calico-node.service └─21949 /usr/bin/docker run --net=host --privileged --name=calico-node -e ETCD_ENDPOINTS=http://172.21.1.201:2379 -e NODENAME= -e IP= -e NO_DEFAULT_POOLS= -e AS= -e CALICO_LIBNE...Sep 27 10:57:28 k1 systemd[1]: Started calicoctl node.Sep 27 10:57:28 k1 systemd[1]: Starting calicoctl node...Sep 27 10:57:28 k1 docker[21949]: Skipping datastore connection testSep 27 10:57:28 k1 docker[21949]: IPv4 address 172.21.1.200 discovered on interface eth0Sep 27 10:57:28 k1 docker[21949]: No AS number configured on node resource, using global valueSep 27 10:57:28 k1 docker[21949]: Using node name: k1Sep 27 10:57:29 k1 docker[21949]: time=\"2017-09-27T02:57:29Z\" level=info msg=\"Loading config from environment\"Sep 27 10:57:29 k1 docker[21949]: Starting libnetwork serviceSep 27 10:57:29 k1 docker[21949]: Calico node started successfully 安装calico/cni-plugin1234$ wget https://github.com/projectcalico/cni-plugin/releases/download/v1.10.0/calico$ wget https://github.com/projectcalico/cni-plugin/releases/download/v1.10.0/calico-ipam$ chmod +x calico calico-ipam$ mv calico calico-ipam /usr/bin cni-plugin需要标准的CNI配置文件，创建配置文件。 1234567891011121314151617181920$ mkdir -p /etc/cni/net.d$ cat &gt;/etc/cni/net.d/10-calico.conf &lt;&lt;EOF&#123; \"name\": \"calico-k8s-network\", \"cniVersion\": \"0.1.0\", \"type\": \"calico\", \"etcd_endpoints\": \"http://172.21.1.201:2379\", \"log_level\": \"info\", \"ipam\": &#123; \"type\": \"calico-ipam\", \"k8s_api_root\": \"http://127.0.0.1:8080\" &#125;, \"policy\": &#123; \"type\": \"k8s\" &#125;, \"kubernetes\": &#123; \"kubeconfig\": \"/etc/cni/net.d/calico-kubeconfig\" &#125;&#125;EOF 注意：policy选项为k8s,使用Kubernetes Network Policy来定义网络策略. 这里需要一个calico-kubeconfig的配置文件。在/etc/cni/net.d下创建calico-kubeconfig配置文件 12345678910111213141516# Kubeconfig file for Calico CNI plugin.apiVersion: v1kind: Configclusters:- name: local cluster: insecure-skip-tls-verify: true server: https://172.21.1.200:8080users:- name: calicocontexts:- name: calico-context context: cluster: local user: calicocurrent-context: calico-context 安装CNI plugin 123$ wget https://github.com/containernetworking/cni/releases/download/v0.3.0/cni-v0.3.0.tgz$ tar -zxvf cni-v0.3.0.tgz$ cp loopback /opt/cni/bin/ 安装calico networkpolicy-controller创建yaml文件，文件地址下载地址： https://docs.projectcalico.org/v2.5/getting-started/kubernetes/installation/policy-controller.yaml 内容如下:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# Calico Version v2.5.1# https://docs.projectcalico.org/v2.5/releases#v2.5.1# This manifest includes the following component versions:# calico/kube-policy-controller:v0.7.0# Create this manifest using kubectl to deploy# the Calico policy controller on Kubernetes.# It deploys a single instance of the policy controller.apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: calico-policy-controller namespace: kube-system labels: k8s-app: calico-policyspec: # Only a single instance of the policy controller should be # active at a time. Since this pod is run as a Deployment, # Kubernetes will ensure the pod is recreated in case of failure, # removing the need for passive backups. replicas: 1 strategy: type: Recreate template: metadata: name: calico-policy-controller namespace: kube-system labels: k8s-app: calico-policy spec: hostNetwork: true containers: - name: calico-policy-controller # Make sure to pin this to your desired version. image: quay.io/calico/kube-policy-controller:v0.7.0 env: # Configure the policy controller with the location of # your etcd cluster. - name: ETCD_ENDPOINTS value: &quot;&lt;ETCD_ENDPOINTS&gt;&quot; # Location of the Kubernetes API - this shouldn&apos;t need to be # changed so long as it is used in conjunction with # CONFIGURE_ETC_HOSTS=&quot;true&quot;. - name: K8S_API value: &quot;https://kubernetes.default:443&quot; # Configure /etc/hosts within the container to resolve # the kubernetes.default Service to the correct clusterIP # using the environment provided by the kubelet. # This removes the need for KubeDNS to resolve the Service. - name: CONFIGURE_ETC_HOSTS value: &quot;true&quot; 需要修改3处地址：image(镜像名称),ETCD_ENDPOINTS(ETCD地址),K8S_API(kubenetes 的API地址) 修改kubelet需要将kubelet中的网络指定为calico ,修改/usr/lib/system.d/system/kubelet.service，加入如下参数 123--network-plugin=cni--cni-conf-dir=/etc/cni/net.d--cni-bin-dir=/opt/cni/bin 注意：kubernetes1.4版本之前不支持cni-conf-dir和cni-bin-dir参数。替换成–network-plugin-dir=/etc/cni/net.d","categories":[{"name":"docker","slug":"docker","permalink":"http://www.badwolfbay.cn/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.badwolfbay.cn/tags/docker/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://www.badwolfbay.cn/tags/kubernetes/"}]},{"title":"kubernetes上部署fluentd采集日志","slug":"kubernetes-fluentd","date":"2017-09-25T14:29:31.000Z","updated":"2017-09-25T15:01:40.000Z","comments":true,"path":"2017/09/25/kubernetes-fluentd/","link":"","permalink":"http://www.badwolfbay.cn/2017/09/25/kubernetes-fluentd/","excerpt":"安装es集群假设es集群在k8s集群外,不要使用root用户。这里安装的版本是2.4.0 tar -zxvf elasticsearch-2.4.0.tar.gz 修改config文件夹下的elasticsearch.yml 12345678910cluster.name: elk_clusternode.name: elk_node01path.data: /csdbomc/elasticsearch-2.4.0/datapath.logs: /csdbomc/elasticsearch-2.4.0/logsnetwork.host: 172.21.0.201network.port: 9201http.cors.enabled : true //http.cors.allow-origin: \"/.*/\"http.cors.allow-methods : OPTIONS, HEAD, GET, POST, PUT, DELETEhttp.cors.allow-headers : \"X-Requested-With,X-Auth-Token,Content-Type, Content-Length, Authorization\" 到bin目录下执行（需要提前安装java） ./elasticsearch -d 制作fluent镜像Dockerfile内容如下: 123456789101112131415FROM badwolf/fluentd-es-image# Ensure there are enough file descriptors for running Fluentd.#RUN ulimit -n 65536# Disable prompts from apt.# Copy the Fluentd configuration file.COPY td-agent.conf /etc/td-agent/td-agent.confENV LD_PRELOAD /opt/td-agent/embedded/lib/libjemalloc.so# Run the Fluentd service.ENTRYPOINT [\"td-agent\"]","text":"安装es集群假设es集群在k8s集群外,不要使用root用户。这里安装的版本是2.4.0 tar -zxvf elasticsearch-2.4.0.tar.gz 修改config文件夹下的elasticsearch.yml 12345678910cluster.name: elk_clusternode.name: elk_node01path.data: /csdbomc/elasticsearch-2.4.0/datapath.logs: /csdbomc/elasticsearch-2.4.0/logsnetwork.host: 172.21.0.201network.port: 9201http.cors.enabled : true //http.cors.allow-origin: \"/.*/\"http.cors.allow-methods : OPTIONS, HEAD, GET, POST, PUT, DELETEhttp.cors.allow-headers : \"X-Requested-With,X-Auth-Token,Content-Type, Content-Length, Authorization\" 到bin目录下执行（需要提前安装java） ./elasticsearch -d 制作fluent镜像Dockerfile内容如下: 123456789101112131415FROM badwolf/fluentd-es-image# Ensure there are enough file descriptors for running Fluentd.#RUN ulimit -n 65536# Disable prompts from apt.# Copy the Fluentd configuration file.COPY td-agent.conf /etc/td-agent/td-agent.confENV LD_PRELOAD /opt/td-agent/embedded/lib/libjemalloc.so# Run the Fluentd service.ENTRYPOINT [\"td-agent\"] td-agent.conf的内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307# This configuration file for Fluentd / td-agent is used# to watch changes to Docker log files. The kubelet creates symlinks that# capture the pod name, namespace, container name &amp; Docker container ID# to the docker logs for pods in the /var/log/containers directory on the host.# If running this fluentd configuration in a Docker container, the /var/log# directory should be mounted in the container.## These logs are then submitted to Elasticsearch which assumes the# installation of the fluent-plugin-elasticsearch &amp; the# fluent-plugin-kubernetes_metadata_filter plugins.# See https://github.com/uken/fluent-plugin-elasticsearch &amp;# https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter for# more information about the plugins.# Maintainer: Jimmi Dyson &lt;jimmidyson@gmail.com&gt;## Example# =======# A line in the Docker log file might look like this JSON:## &#123;\"log\":\"2014/09/25 21:15:03 Got request with path wombat\\n\",# \"stream\":\"stderr\",# \"time\":\"2014-09-25T21:15:03.499185026Z\"&#125;## The time_format specification below makes sure we properly# parse the time format produced by Docker. This will be# submitted to Elasticsearch and should appear like:# $ curl 'http://elasticsearch-logging:9200/_search?pretty'# ...# &#123;# \"_index\" : \"logstash-2014.09.25\",# \"_type\" : \"fluentd\",# \"_id\" : \"VBrbor2QTuGpsQyTCdfzqA\",# \"_score\" : 1.0,# \"_source\":&#123;\"log\":\"2014/09/25 22:45:50 Got request with path wombat\\n\",# \"stream\":\"stderr\",\"tag\":\"docker.container.all\",# \"@timestamp\":\"2014-09-25T22:45:50+00:00\"&#125;# &#125;,# ...## The Kubernetes fluentd plugin is used to write the Kubernetes metadata to the log# record &amp; add labels to the log record if properly configured. This enables users# to filter &amp; search logs on any metadata.# For example a Docker container's logs might be in the directory:## /var/lib/docker/containers/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b## and in the file:## 997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b-json.log## where 997599971ee6... is the Docker ID of the running container.# The Kubernetes kubelet makes a symbolic link to this file on the host machine# in the /var/log/containers directory which includes the pod name and the Kubernetes# container name:## synthetic-logger-0.25lps-pod_default_synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log# -&gt;# /var/lib/docker/containers/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b-json.log## The /var/log directory on the host is mapped to the /var/log directory in the container# running this instance of Fluentd and we end up collecting the file:## /var/log/containers/synthetic-logger-0.25lps-pod_default_synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log## This results in the tag:## var.log.containers.synthetic-logger-0.25lps-pod_default_synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log## The Kubernetes fluentd plugin is used to extract the namespace, pod name &amp; container name# which are added to the log message as a kubernetes field object &amp; the Docker container ID# is also added under the docker field object.# The final tag is:## kubernetes.var.log.containers.synthetic-logger-0.25lps-pod_default_synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log## And the final log record look like:## &#123;# \"log\":\"2014/09/25 21:15:03 Got request with path wombat\\n\",# \"stream\":\"stderr\",# \"time\":\"2014-09-25T21:15:03.499185026Z\",# \"kubernetes\": &#123;# \"namespace\": \"default\",# \"pod_name\": \"synthetic-logger-0.25lps-pod\",# \"container_name\": \"synth-lgr\"# &#125;,# \"docker\": &#123;# \"container_id\": \"997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b\"# &#125;# &#125;## This makes it easier for users to search for logs by pod name or by# the name of the Kubernetes container regardless of how many times the# Kubernetes pod has been restarted (resulting in a several Docker container IDs).## TODO: Propagate the labels associated with a container along with its logs# so users can query logs using labels as well as or instead of the pod name# and container name. This is simply done via configuration of the Kubernetes# fluentd plugin but requires secrets to be enabled in the fluent pod. This is a# problem yet to be solved as secrets are not usable in static pods which the fluentd# pod must be until a per-node controller is available in Kubernetes.# Prevent fluentd from handling records containing its own logs. Otherwise# it can lead to an infinite loop, when error in sending one message generates# another message which also fails to be sent and so on.&lt;match fluent.**&gt; type null&lt;/match&gt;# Example:# &#123;\"log\":\"[info:2016-02-16T16:04:05.930-08:00] Some log text here\\n\",\"stream\":\"stdout\",\"time\":\"2016-02-17T00:04:05.931087621Z\"&#125;&lt;source&gt; type tail path /var/log/containers/*.log pos_file /var/log/es-containers.log.pos time_format %Y-%m-%dT%H:%M:%S.%NZ tag kubernetes.* format json read_from_head true&lt;/source&gt;# Example:# 2015-12-21 23:17:22,066 [salt.state ][INFO ] Completed state [net.ipv4.ip_forward] at time 23:17:22.066081&lt;source&gt; type tail format /^(?&lt;time&gt;[^ ]* [^ ,]*)[^\\[]*\\[[^\\]]*\\]\\[(?&lt;severity&gt;[^ \\]]*) *\\] (?&lt;message&gt;.*)$/ time_format %Y-%m-%d %H:%M:%S path /var/log/salt/minion pos_file /var/log/es-salt.pos tag salt&lt;/source&gt;# Example:# Dec 21 23:17:22 gke-foo-1-1-4b5cbd14-node-4eoj startupscript: Finished running startup script /var/run/google.startup.script&lt;source&gt; type tail format syslog path /var/log/startupscript.log pos_file /var/log/es-startupscript.log.pos tag startupscript&lt;/source&gt;# Examples:# time=\"2016-02-04T06:51:03.053580605Z\" level=info msg=\"GET /containers/json\"# time=\"2016-02-04T07:53:57.505612354Z\" level=error msg=\"HTTP Error\" err=\"No such image: -f\" statusCode=404&lt;source&gt; type tail format /^time=\"(?&lt;time&gt;[^)]*)\" level=(?&lt;severity&gt;[^ ]*) msg=\"(?&lt;message&gt;[^\"]*)\"( err=\"(?&lt;error&gt;[^\"]*)\")?( statusCode=($&lt;status_code&gt;\\d+))?/ path /var/log/docker.log pos_file /var/log/es-docker.log.pos tag docker&lt;/source&gt;# Example:# 2016/02/04 06:52:38 filePurge: successfully removed file /var/etcd/data/member/wal/00000000000006d0-00000000010a23d1.wal&lt;source&gt; type tail # Not parsing this, because it doesn't have anything particularly useful to # parse out of it (like severities). format none path /var/log/etcd.log pos_file /var/log/es-etcd.log.pos tag etcd&lt;/source&gt;# Multi-line parsing is required for all the kube logs because very large log# statements, such as those that include entire object bodies, get split into# multiple lines by glog.# Example:# I0204 07:32:30.020537 3368 server.go:1048] POST /stats/container/: (13.972191ms) 200 [[Go-http-client/1.1] 10.244.1.3:40537]&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\\w\\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\\w)(?&lt;time&gt;\\d&#123;4&#125; [^\\s]*)\\s+(?&lt;pid&gt;\\d+)\\s+(?&lt;source&gt;[^ \\]]+)\\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/kubelet.log pos_file /var/log/es-kubelet.log.pos tag kubelet&lt;/source&gt;# Example:# I1118 21:26:53.975789 6 proxier.go:1096] Port \"nodePort for kube-system/default-http-backend:http\" (:31429/tcp) was open before and is still needed&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\\w\\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\\w)(?&lt;time&gt;\\d&#123;4&#125; [^\\s]*)\\s+(?&lt;pid&gt;\\d+)\\s+(?&lt;source&gt;[^ \\]]+)\\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/kube-proxy.log pos_file /var/log/es-kube-proxy.log.pos tag kube-proxy&lt;/source&gt;# Example:# I0204 07:00:19.604280 5 handlers.go:131] GET /api/v1/nodes: (1.624207ms) 200 [[kube-controller-manager/v1.1.3 (linux/amd64) kubernetes/6a81b50] 127.0.0.1:38266]&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\\w\\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\\w)(?&lt;time&gt;\\d&#123;4&#125; [^\\s]*)\\s+(?&lt;pid&gt;\\d+)\\s+(?&lt;source&gt;[^ \\]]+)\\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/kube-apiserver.log pos_file /var/log/es-kube-apiserver.log.pos tag kube-apiserver&lt;/source&gt;# Example:# I0204 06:55:31.872680 5 servicecontroller.go:277] LB already exists and doesn't need update for service kube-system/kube-ui&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\\w\\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\\w)(?&lt;time&gt;\\d&#123;4&#125; [^\\s]*)\\s+(?&lt;pid&gt;\\d+)\\s+(?&lt;source&gt;[^ \\]]+)\\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/kube-controller-manager.log pos_file /var/log/es-kube-controller-manager.log.pos tag kube-controller-manager&lt;/source&gt;# Example:# W0204 06:49:18.239674 7 reflector.go:245] pkg/scheduler/factory/factory.go:193: watch of *api.Service ended with: 401: The event in requested index is outdated and cleared (the requested history has been cleared [2578313/2577886]) [2579312]&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\\w\\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\\w)(?&lt;time&gt;\\d&#123;4&#125; [^\\s]*)\\s+(?&lt;pid&gt;\\d+)\\s+(?&lt;source&gt;[^ \\]]+)\\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/kube-scheduler.log pos_file /var/log/es-kube-scheduler.log.pos tag kube-scheduler&lt;/source&gt;# Example:# I1104 10:36:20.242766 5 rescheduler.go:73] Running Rescheduler&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\\w\\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\\w)(?&lt;time&gt;\\d&#123;4&#125; [^\\s]*)\\s+(?&lt;pid&gt;\\d+)\\s+(?&lt;source&gt;[^ \\]]+)\\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/rescheduler.log pos_file /var/log/es-rescheduler.log.pos tag rescheduler&lt;/source&gt;# Example:# I0603 15:31:05.793605 6 cluster_manager.go:230] Reading config from path /etc/gce.conf&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\\w\\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\\w)(?&lt;time&gt;\\d&#123;4&#125; [^\\s]*)\\s+(?&lt;pid&gt;\\d+)\\s+(?&lt;source&gt;[^ \\]]+)\\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/glbc.log pos_file /var/log/es-glbc.log.pos tag glbc&lt;/source&gt;# Example:# I0603 15:31:05.793605 6 cluster_manager.go:230] Reading config from path /etc/gce.conf&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\\w\\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\\w)(?&lt;time&gt;\\d&#123;4&#125; [^\\s]*)\\s+(?&lt;pid&gt;\\d+)\\s+(?&lt;source&gt;[^ \\]]+)\\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/cluster-autoscaler.log pos_file /var/log/es-cluster-autoscaler.log.pos tag cluster-autoscaler&lt;/source&gt;&lt;filter kubernetes.**&gt; type kubernetes_metadata kubernetes_url http://172.21.1.200:8080&lt;/filter&gt;&lt;match **&gt; type elasticsearch log_level info include_tag_key true host 172.21.2.40 port 9211 logstash_format true # Set the chunk limit the same as for fluentd-gcp. buffer_chunk_limit 2M # Cap buffer memory usage to 2MiB/chunk * 32 chunks = 64 MiB buffer_queue_limit 32 flush_interval 5s # Never wait longer than 5 minutes between retries. max_retry_wait 30 # Disable the limit on the number of retries (retry forever). disable_retry_limit # Use multiple threads for processing. num_threads 8&lt;/match&gt; 修改其中的kubernetes_url地址为kubernetes的master节点地址修改host,port分别为es的地址和端口 部署fluent镜像使用daemonset部署fluent可以使得fluent在每台主机上部署一个POD cat fluentd-es.yaml 123456789101112131415161718192021222324252627282930313233343536apiVersion: extensions/v1beta1kind: DaemonSetmetadata: name: fluentd-es namespace: kube-system labels: k8s-app: fluentd-esspec: template: metadata: labels: k8s-app: fluentd-es spec: containers: - name: fluentd-es image: 172.21.3.106:5000/fluentd-es resources: limits: memory: 200Mi requests: cpu: 250m memory: 200Mi volumeMounts: - name: varlog mountPath: /var/log - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true terminationGracePeriodSeconds: 30 volumes: - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers","categories":[{"name":"docker","slug":"docker","permalink":"http://www.badwolfbay.cn/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.badwolfbay.cn/tags/docker/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://www.badwolfbay.cn/tags/kubernetes/"}]},{"title":"Docker镜像中国加速","slug":"docker-image-mirror","date":"2017-09-25T14:23:15.000Z","updated":"2017-09-25T15:01:45.000Z","comments":true,"path":"2017/09/25/docker-image-mirror/","link":"","permalink":"http://www.badwolfbay.cn/2017/09/25/docker-image-mirror/","excerpt":"通过 Docker 官方镜像加速，中国区用户能够快速访问最流行的 Docker 镜像。该镜像托管于中国大陆，本地用户现在将会享受到更快的下载速度和更强的稳定性，从而能够更敏捷地开发和交付 Docker 化应用。 Docker 中国官方镜像加速可通过 registry.docker-cn.com 访问。该镜像库只包含流行的公有镜像。私有镜像仍需要从美国镜像库中拉取。 您可以使用以下命令直接从该镜像加速地址进行拉取： 1$ docker pull registry.docker-cn.com/myname/myrepo:mytag 例如: 1$ docker pull registry.docker-cn.com/library/ubuntu:16.04 注: 除非您修改了 Docker 守护进程的 --registry-mirror 参数 (见下文), 否则您将需要完整地指定官方镜像的名称。例如，library/ubuntu、library/redis、library/nginx。","text":"通过 Docker 官方镜像加速，中国区用户能够快速访问最流行的 Docker 镜像。该镜像托管于中国大陆，本地用户现在将会享受到更快的下载速度和更强的稳定性，从而能够更敏捷地开发和交付 Docker 化应用。 Docker 中国官方镜像加速可通过 registry.docker-cn.com 访问。该镜像库只包含流行的公有镜像。私有镜像仍需要从美国镜像库中拉取。 您可以使用以下命令直接从该镜像加速地址进行拉取： 1$ docker pull registry.docker-cn.com/myname/myrepo:mytag 例如: 1$ docker pull registry.docker-cn.com/library/ubuntu:16.04 注: 除非您修改了 Docker 守护进程的 --registry-mirror 参数 (见下文), 否则您将需要完整地指定官方镜像的名称。例如，library/ubuntu、library/redis、library/nginx。 使用 –registry-mirror 配置 Docker 守护进程您可以配置 Docker 守护进程默认使用 Docker 官方镜像加速。这样您可以默认通过官方镜像加速拉取镜像，而无需在每次拉取时指定 registry.docker-cn.com。 您可以在 Docker 守护进程启动时传入 –registry-mirror 参数： 1$ docker --registry-mirror=https://registry.docker-cn.com daemon 为了永久性保留更改，您可以修改 /etc/docker/daemon.json 文件并添加上 registry-mirrors 键值。 123&#123; \"registry-mirrors\": [\"https://registry.docker-cn.com\"]&#125; 修改保存后重启 Docker 以使配置生效。 注: 您也可以使用适用于 Mac 的 Docker 和适用于 Windows 的 Docker 来进行设置。 原文连接: https://www.docker-cn.com/registry-mirror","categories":[{"name":"docker","slug":"docker","permalink":"http://www.badwolfbay.cn/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.badwolfbay.cn/tags/docker/"},{"name":"image","slug":"image","permalink":"http://www.badwolfbay.cn/tags/image/"}]},{"title":"调用Harbor RestAPI增加认证","slug":"harbor-api-token","date":"2017-09-25T02:57:19.000Z","updated":"2017-09-25T03:09:25.000Z","comments":true,"path":"2017/09/25/harbor-api-token/","link":"","permalink":"http://www.badwolfbay.cn/2017/09/25/harbor-api-token/","excerpt":"","text":"1.通过Rest API访问Harbor需要Token认证信息 curl -u username:password http://172.21.1.19/api/users 但是通过restclient访问时像curl一样添加-u参数，需要在Header中增加参数 Authorization: Basic base64encoded(user:pass) 如： 123Builder builder = restClient.target(url + \"/api/users\").request();String auth = Base64.getEncoder().encodeToString(\"user:password\".getBytes())；builder.header(\"Authorization\",\"Basic \" + auth); 在JAVA8中，可以直接使用Base64工具类。 参考链接: https://stackoverflow.com/questions/29116595/how-to-send-u-data-of-curl-in-rest-client","categories":[{"name":"harbor","slug":"harbor","permalink":"http://www.badwolfbay.cn/categories/harbor/"}],"tags":[{"name":"harbor","slug":"harbor","permalink":"http://www.badwolfbay.cn/tags/harbor/"}]},{"title":"MAC上安装docker","slug":"install-docker-via-dlite","date":"2017-09-21T13:09:47.000Z","updated":"2017-09-21T13:19:49.000Z","comments":true,"path":"2017/09/21/install-docker-via-dlite/","link":"","permalink":"http://www.badwolfbay.cn/2017/09/21/install-docker-via-dlite/","excerpt":"在MAC上安装docker for mac后，docker程序会在用户登录mac后自动启动，而如果用户没有登录，而是通过ssh远程登录的情况下，docker是无法启动的，在配置launchctl也无法配置自动启动命令。 经过一番搜索后，可以使用dlite来通过命令启动docker。 1.项目地址： https://github.com/nlf/dlite 2.在release中下载编译好的二进制文件，将文件放到PATH下，最简单的放到/usr/local/bin/目录下，然后执行 sudo dlite init 注意需要给dlite可执行权限 chmod +x dlite 3.执行命令后，开始询问创建虚拟机的参数，一路回车，但是最后报错 1234Saving configuration: doneCreating ssh key pair: doneAdding host to ssh config: ERROR!Adding host to ssh config: | open /var/root/.ssh/config: no such file or directory 手动创建.ssh目录以及config文件 sudo mkdir /var/root/.ssh sudo touch /var/root/.ssh/config 然后重新执行sudo dlite init","text":"在MAC上安装docker for mac后，docker程序会在用户登录mac后自动启动，而如果用户没有登录，而是通过ssh远程登录的情况下，docker是无法启动的，在配置launchctl也无法配置自动启动命令。 经过一番搜索后，可以使用dlite来通过命令启动docker。 1.项目地址： https://github.com/nlf/dlite 2.在release中下载编译好的二进制文件，将文件放到PATH下，最简单的放到/usr/local/bin/目录下，然后执行 sudo dlite init 注意需要给dlite可执行权限 chmod +x dlite 3.执行命令后，开始询问创建虚拟机的参数，一路回车，但是最后报错 1234Saving configuration: doneCreating ssh key pair: doneAdding host to ssh config: ERROR!Adding host to ssh config: | open /var/root/.ssh/config: no such file or directory 手动创建.ssh目录以及config文件 sudo mkdir /var/root/.ssh sudo touch /var/root/.ssh/config 然后重新执行sudo dlite init 而后报新的错误 123Creating tool binaries: done Creating tool binaries: |Creating disk: ERROR!signal: trace/BPT trap 需要安装依赖 brew install opam golang libev opam init eval opam config env opam install uri qcow.0.7.0 conf-libev logs fmt qcow-format 然后仍然报错,信息 12Next we'll run a few steps that require sudo, you may be prompted for your password. Creating /etc/resoModifying /etc/exports: ERROR! done 根据github上的issue https://github.com/nlf/dlite/issues/218 问题在于执行sudo dlite init是不能加sudo,再次执行 dlite init 即可 dlite start 执行docker命令报错 12$ docker psError response from daemon: Unable to connect to the virtual machine 执行ssh docker@local.docker 报错。 正常Dlite 会自动添加 local.docker 到 OS X 的 hosts 文件内。 需要手动更改hosts文件 dlite ip 查看ip 为192.168.64.2 sudo vi /etc/hosts 增加一行 1192.168.64.2 local.docker 后执行docker ps就可以了 12$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 可参考链接 http://holys.im/2016/02/22/run-docker-on-osx-with-dlite/","categories":[{"name":"docker","slug":"docker","permalink":"http://www.badwolfbay.cn/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.badwolfbay.cn/tags/docker/"}]},{"title":"Go 指南学习笔记九","slug":"go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b9-9d","date":"2017-09-15T13:17:04.000Z","updated":"2017-09-19T14:20:32.000Z","comments":true,"path":"2017/09/15/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b9-9d/","link":"","permalink":"http://www.badwolfbay.cn/2017/09/15/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b9-9d/","excerpt":"","text":"1.接口，接口为一组方法定义的集合 和其它语言不同，类型实现接口不需要显示声明，不需要implements关键字 定义接口和实现接口互不依赖 1234567891011121314151617181920212223242526272829303132333435type Abser interface &#123; Abs() float64&#125;type MyFloat float64func (f MyFloat) Abs() float64 &#123; if f &lt; 0 &#123; return float64(-f) &#125; return float64(f)&#125;type Vertex struct &#123; X, Y float64&#125;func (v *Vertex) Abs() float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func main() &#123; var a Abser f := MyFloat(-math.Sqrt2) v := Vertex&#123;3, 4&#125; a = f // a MyFloat 实现了 Abser a = &amp;v // a *Vertex 实现了 Abser // 下面一行，v 是一个 Vertex（而不是 *Vertex） // 所以没有实现 Abser。 a = v fmt.Println(a.Abs())&#125;","categories":[{"name":"golang","slug":"golang","permalink":"http://www.badwolfbay.cn/categories/golang/"}],"tags":[]},{"title":"Go 指南学习笔记八","slug":"go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e5-85-ab","date":"2017-09-11T05:22:53.000Z","updated":"2017-09-19T14:21:42.000Z","comments":true,"path":"2017/09/11/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e5-85-ab/","link":"","permalink":"http://www.badwolfbay.cn/2017/09/11/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e5-85-ab/","excerpt":"","text":"1.结构体方法 Go语言不像JAVA，没有类的定义，但是依然可以为结构体定义方法。 123456789101112131415package mainimport ( \"fmt\" \"math\")type Vertex struct &#123; X, Y float64&#125;func (v *Vertex) Abs() float64 &#123; return math.Sqrt(v.X * v.X + v.Y * v.Y)&#125;func main()&#123; v := &amp;Vertex&#123;3,4&#125; fmt.Println(v.Abs()) // 5&#125; 2.还可以对包内任意类型定义任意方法，但是不能对包外的类型或者基础类型定义方法 1234567891011121314151617181920package mainimport ( \"fmt\" \"math\")type MyFloat float64func (f MyFloat) Abs() float64 &#123; if f &lt; 0 &#123; return float64(-f) &#125; return float64(f)&#125;func main()&#123; f := MyFloat(-math.Sqrt2) fmt.Println(f.Abs()) // 1.4142135623730951&#125; 3.方法可以与类型和类型的指针相关联 如1中的Abs方法是作用的*Vertex指针类型上 1234func (v *Vertex) Scale(f float64)&#123; v.X = v.X * f v.Y = v.Y * f&#125; 与 1234func (v Vertex) Scale(f float64)&#123; v.X = v.X * f v.Y = v.Y * f&#125; 的区别 v := *Vertex(3,5) v.Scale(5) 前边的是用*Vertex指针类型接受，是引用传递，所以会改变接受者v的原始值，而后边的是用变量（后者说是对象）接受，是值传递，会对v进行一份copy,而不会对原始值做更改。","categories":[{"name":"golang","slug":"golang","permalink":"http://www.badwolfbay.cn/categories/golang/"}],"tags":[]},{"title":"Go 指南学习笔记七","slug":"go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b8-83","date":"2017-09-07T13:37:40.000Z","updated":"2017-09-19T14:22:42.000Z","comments":true,"path":"2017/09/07/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b8-83/","link":"","permalink":"http://www.badwolfbay.cn/2017/09/07/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b8-83/","excerpt":"","text":"闭包 函数也是一个值，也可以像其它值一样传递。函数值也可以作为参数或者返回值 闭包是一个函数值，他引用了函数体之外的变量 这个函数值可以对引用的变量进行修改或者赋值 1234567891011121314151617181920package mainimport ( \"fmt\")func adder() func(int) int &#123; sum := 0 return func(x int) int &#123; sum += x return sum &#125;&#125;func main() &#123; pos, neg := adder(), adder() for i := 0; i &lt; 10; i++ &#123; fmt.Println(pos(i), neg(-2*i)) &#125;&#125; 输出结果： 12345678910111213[Running] go run \"/Users/badwolf/Documents/go/hello/tempCodeRunnerFile.go\"0 01 -23 -66 -1210 -2015 -3021 -4228 -5636 -7245 -90[Done] exited with code=0 in 0.605 seconds","categories":[{"name":"golang","slug":"golang","permalink":"http://www.badwolfbay.cn/categories/golang/"}],"tags":[]},{"title":"zookeeper安装","slug":"zookeeper-e5-ae-89-e8-a3-85","date":"2017-09-06T02:33:09.000Z","updated":"2017-11-01T06:16:24.000Z","comments":true,"path":"2017/09/06/zookeeper-e5-ae-89-e8-a3-85/","link":"","permalink":"http://www.badwolfbay.cn/2017/09/06/zookeeper-e5-ae-89-e8-a3-85/","excerpt":"","text":"1.下载安装文件，下载地址：http://mirrors.hust.edu.cn/apache/zookeeper/ 这里的下载的版本为zookeeper-3.4.10.tar.gz 2.解压下载的安装文件 tar -zxvf&nbsp;zookeeper-3.4.10.tar.gz 3.修改配置文件 zookeeper-3.4.10/confmv zoo_sample.cfg zoo.cfg zoo.cfg可以根据需要修改配置信息,如clientPort=2181 4.启动zookeeper cd ../bin./zkServer.sh start 启动成功信息： ZooKeeper JMX enabled by default Using config: /root/zookeeper-3.4.10/bin/../conf/zoo.cfg Starting zookeeper … STARTED 查看端口占用信息： netstat -an|grep 2181 5.客户端连接测试 ./zkCli.sh -server 127.0.0.1 连接成功后执行help命令可以查看帮助命令 [zk: 127.0.0.1(CONNECTED) 0] help ZooKeeper -server host:port cmd args stat path [watch] set path data [version] ls path [watch] delquota [-n|-b] path ls2 path [watch] setAcl path acl setquota -n|-b val path history&nbsp; redo cmdno printwatches on|off delete path [version] sync path listquota path rmr path get path [watch] create [-s] [-e] path data acl addauth scheme auth quit&nbsp; getAcl path close&nbsp; connect host:port","categories":[{"name":"Java","slug":"Java","permalink":"http://www.badwolfbay.cn/categories/Java/"}],"tags":[]},{"title":"Go 指南学习笔记六","slug":"go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e5-85-ad","date":"2017-09-05T01:48:36.000Z","updated":"2017-09-19T14:23:32.000Z","comments":true,"path":"2017/09/05/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e5-85-ad/","link":"","permalink":"http://www.badwolfbay.cn/2017/09/05/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e5-85-ad/","excerpt":"","text":"1.map map在使用之前必须使用make来创建，值为nil的map是空的，并且不能对它赋值 1234567891011121314151617package mainimport ( \"fmt\")type Vertex struct&#123; Lat, Long float64&#125;var m map[string]Vertexfunc main() &#123; m = make(map[string]Vertex) m[\"Bell Labs\"] = Vertex&#123;40.68433, -74.39967&#125; fmt.Println(m[\"Bell Labs\"])// &#123;40.68433 -74.39967&#125;&#125; 2.和结构体语法类似 12345var n = map[string]Vertex &#123; \"Bell Labs\": Vertex&#123;40.68433, -74.39967,&#125;, \"Google\":Vertex&#123;37.42202, -122.08408,&#125;,&#125;fmt.Println(n) //map[Bell Labs:&#123;40.68433 -74.39967&#125; Google:&#123;37.42202 -122.08408&#125;] 如果map的value值只是一个类型，可以在{}中将类型省略 1234var k = map[string]Vertex&#123; \"Bell Labs\": &#123;40.68433, -74.39967&#125;, \"Google\": &#123;37.42202, -122.08408&#125;,&#125; 3.修改map 插入或者修改元素: m[key] =&nbsp;elem 获得元素:&nbsp;elem = m[key] 删除元素: delete(m,key) 检测是否存在: elem, ok = m[key]","categories":[{"name":"golang","slug":"golang","permalink":"http://www.badwolfbay.cn/categories/golang/"}],"tags":[]},{"title":"Go 指南学习笔记五","slug":"go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-ba-94","date":"2017-09-03T15:28:42.000Z","updated":"2017-09-19T14:25:04.000Z","comments":true,"path":"2017/09/03/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-ba-94/","link":"","permalink":"http://www.badwolfbay.cn/2017/09/03/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-ba-94/","excerpt":"","text":"1.数组：类型[n]T是有n个值的类型为T的数组 var a [10] int 变量a是一个有10个整数的数组。 数组不能改变大小 12345678910package mainimport \"fmt\"func main() &#123; var a [10]string a[0] = \"hello\" a[1] = \"world\" fmt.Println(a[0], a[1]) //hello world fmt.Println(a) // [hello world&#125; 2.slice(切片),[]T为一个类型为T的slice,len(s)返回切片s的长度 123456789101112131415s := []int&#123;2, 3, 5, 7, 11, 13&#125;fmt.Println(\"s == \", s)for i := 0; i &lt; len(s); i++ &#123; fmt.Printf(\"s[%d] = %d\\n\", i, s[i])&#125;//输出结果s == [2 3 5 7 11 13]s[0] = 2s[1] = 3s[2] = 5s[3] = 7s[4] = 11s[5] = 13 3.slice 可以包含任意的类型，包括另一个 slice。 123456game := [][] string&#123; []string&#123;\"\",\"\",\"\"&#125;, []string&#123;\"\",\"\",\"\"&#125;, []string&#123;\"\",\"\",\"\"&#125;,&#125; 4.对slice切片 s[lo:hi] // 包含lo元素，不包含hi元素 5.构造slice,slice由make创建，这会分配一个全是零值的数组并返回一个slice并指向这个数组 1a := make([]int, 5) 可以传递第三个参数来执行容量 1b := make([]int, 0 , 5) // len(b) = 0, cap(b) = 5 如： 1234567891011121314func printlnSlice(s string, x []int) &#123; fmt.Printf(\"%s len=%d, cap=%d %v\\n\", s, len(x), cap(x), x)&#125;func main() &#123; a := make([]int, 5) printlnSlice(\"a\", a) // a len=5, cap=5 [0 0 0 0 0] b := make([]int, 0, 5) printlnSlice(\"b\", b) // b len=0, cap=5 [] c := b[:2] printlnSlice(\"c\", c) // c len=2, cap=5 [0 0] d := c[2:5] printlnSlice(\"d\", d) //d len=3, cap=3 [0 0 0]&#125; 6.向slice结尾添加元素，append 1234var a []intappend(a, 0)append(a, 1)append(a, 2, 3, 4) 如果slice底层数组的不能分配更多的数组时，会自动分配一个更大的数组，返回的slice指向新的数组。 7.切片是数组之上的抽象数据类型。 初始化不同,切片不需要指定固定长度:var a [10]int//数组var a []int//切片 切片的零值是nil 更多的slice切片：用法与本质","categories":[{"name":"golang","slug":"golang","permalink":"http://www.badwolfbay.cn/categories/golang/"}],"tags":[]},{"title":"Go 指南学习笔记四","slug":"go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e5-9b-9b","date":"2017-09-02T12:57:40.000Z","updated":"2017-09-19T14:25:52.000Z","comments":true,"path":"2017/09/02/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e5-9b-9b/","link":"","permalink":"http://www.badwolfbay.cn/2017/09/02/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e5-9b-9b/","excerpt":"","text":"1.结构体struct 12345678910type Vertex struct &#123; X int Y int&#125;func main()&#123; v := Vertex&#123;1,2&#125; v.X = 4 fmt.Println(v.X) // 4&#125; 2.结构体指针 1234v := Vertex&#123;1,2&#125;p := &amp;amp;vp.X = 1e9fmt.Println(p.X) //1000000000 3.结构体语法，可以仅列出部分字段；&amp;可以指向结构体的指针 1234567var ( v1 = Vertex&#123;1, 2&#125; v2 = Vertex&#123;X: 1&#125; v3 = Vertex&#123;&#125; p = *Vertex&#123;1, 2&#125;)fmt.Println(v1, v2, v3, p)//&#123;1 2&#125; &#123;1 0&#125; &#123;0 0&#125; *&#123;1 2&#125;","categories":[{"name":"golang","slug":"golang","permalink":"http://www.badwolfbay.cn/categories/golang/"}],"tags":[]},{"title":"Go 指南学习笔记三","slug":"go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b8-89","date":"2017-09-01T12:45:41.000Z","updated":"2017-11-07T07:10:19.000Z","comments":true,"path":"2017/09/01/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b8-89/","link":"","permalink":"http://www.badwolfbay.cn/2017/09/01/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b8-89/","excerpt":"","text":"1.指针：指针保存了变量的内存地址。 *T是指向类型T的值指针，其零值是nil &amp;符号会生成一个其作用对象的指针 12345678var p *intfmt.Println(p)i := 42p = &amp;ifmt.Println(p) 输出结果为 *表示指针指向底层的值 1fmt.Println(*p) 并且可以通过修改指针修改底层的值 1*p = 21 这就是常说的”间接引用”。与C语言不同，go语言的指针没有运算。","categories":[{"name":"golang","slug":"golang","permalink":"http://www.badwolfbay.cn/categories/golang/"}],"tags":[]},{"title":"利用Dockerhub+github自定义制作镜像","slug":"e5-88-a9-e7-94-a8dockerhubgithub-e8-87-aa-e5-ae-9a-e4-b9-89-e5-88-b6-e4-bd-9c-e9-95-9c-e5-83-8f","date":"2017-08-31T15:00:13.000Z","updated":"2017-09-19T13:59:19.000Z","comments":true,"path":"2017/08/31/e5-88-a9-e7-94-a8dockerhubgithub-e8-87-aa-e5-ae-9a-e4-b9-89-e5-88-b6-e4-bd-9c-e9-95-9c-e5-83-8f/","link":"","permalink":"http://www.badwolfbay.cn/2017/08/31/e5-88-a9-e7-94-a8dockerhubgithub-e8-87-aa-e5-ae-9a-e4-b9-89-e5-88-b6-e4-bd-9c-e9-95-9c-e5-83-8f/","excerpt":"","text":"Dockerhub可以根据github工程中Dockerfile自动生成镜像，一般情况下，我们需要google下gcr的镜像，因为网络原因连接不上，我们可以将Dockerfile文件提交到github,然后生成我们自己的镜像，如： 前提是已经注册自己的Dockerhub帐号，登录https://hub.docker.com 点击右上角Create -&gt; Create Automated Build 后登录自己的github帐号 从自己的github工程中选择要创建镜像的工程 后输入要生成的镜像名称 在Build Setting的Tab页中输入Dockerfile的位置以及tag /目录为相对于github中工程的位置，如github中Dockerfile在/centos下 则输入/centos，再点击save changes后，点击Trigger后就可以构建镜像了，后续如果github中代码有更改，构建动作会自动触发。点击build details可以查看每次构建日志","categories":[{"name":"golang","slug":"golang","permalink":"http://www.badwolfbay.cn/categories/golang/"}],"tags":[]},{"title":"Go 指南学习笔记二","slug":"go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-ba-8c","date":"2017-08-30T13:18:46.000Z","updated":"2017-09-19T14:27:52.000Z","comments":true,"path":"2017/08/30/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-ba-8c/","link":"","permalink":"http://www.badwolfbay.cn/2017/08/30/go-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-ba-8c/","excerpt":"","text":"1.for循环 go语言只有一个循环语句，即for. 1234sum := 0for i:= 0;i&lt;10;i++&#123; sum += i&#125; 不像java,python等，条件表达式不需要()小括号，循环体需要{} 初始化条件和后置判断条件不是必须的，如for ; i&lt;10; {} 在java等语言中while循环在go语言中写法 123for i &lt; 10 &#123; sum += i&#125; 死循环 123for &#123; sum += i&#125; 2.if语句 同for循环一样,if语句的判断条件语句也不需要() 12if i&lt;10 &#123;&#125; 同for循环一样，条件之前也可以是一个简单的语句 1234567i := 10if j := 10; i&lt;j &#123; return j&#125; else &#123; return i&#125; 3.switch语句 123456789101112131415161718package mainimport ( \"fmt\" \"runtime\")func main() &#123; fmt.Print(\"Go runs on \") switch os := runtime.GOOS; os &#123; case \"darwin\": fmt.Println(\"OS X.\") case \"linux\": fmt.Println(\"Linux.\") default: fmt.Printf(\"%s.\", os) &#125;&#125; 按照条件从上到下执行，直到匹配到成功为止，执行成功后，后边的条件不再执行 没有条件的switch，如switch {},同switch true {}一样 4.defer语句 defer 语句会延迟函数的执行直到上层函数返回。 延迟调用的参数会立刻生成，但是在上层函数返回前函数都不会被调用 12345678package mainimport \"fmt\";func main()&#123; defer fmt.Println(\"world&amp;quot;) fmt.Print(\"hello\")&#125; defer栈，延迟的函数调用会被压入一个栈中。 1234567891011package mainimport \"fmt\"func main() &#123; fmt.Println(\"counting\") for i := 0; i &lt; 10; i++ &#123; defer fmt.Println(i) &#125; fmt.Println(\"done\")&#125; 输出结果如下： 12345678910111213[Running] go run \"/Users/badwolf/Documents/go/hello/defer.go\"countingdone9876543210","categories":[{"name":"golang","slug":"golang","permalink":"http://www.badwolfbay.cn/categories/golang/"}],"tags":[]},{"title":"ssh免密码登陆","slug":"ssh-e5-85-8d-e5-af-86-e7-a0-81-e7-99-bb-e9-99-86","date":"2017-08-30T01:56:25.000Z","updated":"2017-09-19T14:09:42.000Z","comments":true,"path":"2017/08/30/ssh-e5-85-8d-e5-af-86-e7-a0-81-e7-99-bb-e9-99-86/","link":"","permalink":"http://www.badwolfbay.cn/2017/08/30/ssh-e5-85-8d-e5-af-86-e7-a0-81-e7-99-bb-e9-99-86/","excerpt":"","text":"有三台机器172.21.3.124/125/126，需要在这三台机器配置免密码登陆能够互相访问 1.在一台机器上执行命令，如172.21.3.124，期间会输入三次回车 ssh-keygen -t rsa 2.命令会在当前用户的家目录的.ssh的目录下生成id_rsa和id_rsa.pub文件，将id_rsa.pub文件copy到其他主机(172.21.3.125)的.ssh/authorized_keys目录下 因为我的是root用户，所以copy到/root/.ssh目录下。 3.这样再登陆172.21.3.125就可以不用输入密码了。需要注意的是 authorized_keys的权限需要是600。(chmod 600 .ssh/authorized_keys) 将id_rsa.pub文件Copy到172.21.3.126上就可以免密码登陆到172.21.3.126了。 将以上的命令和步骤重复在172.21.3.125/126分别执行， 注意已经存在authorized_keys文件不能覆盖，需要在文件内容后追加其他主机的id_rsa.pub的内容。 这样就可以三台机器 间互相免密码访问了。","categories":[{"name":"linux","slug":"linux","permalink":"http://www.badwolfbay.cn/categories/linux/"}],"tags":[]},{"title":"python *args **kwargs理解","slug":"python-args-kwargs-e7-90-86-e8-a7-a3","date":"2017-08-29T06:42:18.000Z","updated":"2017-09-19T14:10:22.000Z","comments":true,"path":"2017/08/29/python-args-kwargs-e7-90-86-e8-a7-a3/","link":"","permalink":"http://www.badwolfbay.cn/2017/08/29/python-args-kwargs-e7-90-86-e8-a7-a3/","excerpt":"","text":"*args表示任意多个无名参数，是个tuple（元组） **kwargs表示关键字参数，是个dict（字典） 这两个是python中的可变参数 注意：同时使用args和**kwargs时，args参数必须在**kwargs前边 123456789def foo(*args, **kwargs): print 'args = ', args print 'kwargs = ', kwargs if name == '__main__': foo(1,2,3,4) foo(a=1, b=2, c=3, d=4) foo(1,2,3,4,a=1, b=2, c=3, b=4) foo('a', 1, None, a=1, b='2', c=3)","categories":[{"name":"python","slug":"python","permalink":"http://www.badwolfbay.cn/categories/python/"}],"tags":[]},{"title":"Go 指南学习笔记一","slug":"golang-tour-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b8-80","date":"2017-08-28T08:37:36.000Z","updated":"2017-09-19T14:28:42.000Z","comments":true,"path":"2017/08/28/golang-tour-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b8-80/","link":"","permalink":"http://www.badwolfbay.cn/2017/08/28/golang-tour-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b8-80/","excerpt":"","text":"Golang提供了官方的学习手册，tour地址：https://tour.go-zh.org同时，鉴于国内的网络环境，可以自己安装进行离线访问Go指南 1go get github.com/Go-zh/tour/gotour 然后就可以得到go tour了 12cd $GOPATH/bin./gotour 2.包 每个 Go 程序都是由包组成的。 程序运行的入口是包 main 。 一般情况下，包名与导入路径的最后一个目录一致。 3.包的导入 12import \"fmt\"import \"math\" 或者更多时候是下面的导入形式 1234import ( \"fmt\" \"math\") 4.大小写 首字母大写的名字是被导出的，可以被其他包引用，名称为小写的名称不会被导出 如： 可以引用fmt.Println()，而不能是fmt.println() 5.函数定义 123func add(x int, y int) int&#123; return x + y&#125; Golang和其他语言不同，变量名在类型之前,函数返回值再最后。 如果参数类型相同，则可以合并，如上可以写成 x, y int 。 函数返回值可以返回多个，形式为(int, int) 6.变量定义 var x ,y 可以定义在包级别或者函数级别。 函数赋值var x int = 1,可以省略类型，如var x = 1。 更可以简写成x :=1,这种情况下不能在函数外使用。 变量在没有初始化为默认为零值： 数值类型为 0 ， 布尔类型为 false ， 字符串为 &quot;&quot; （空字符串）不同类型之间的转换需要显示转换,如 int(i) 7.常量 常量定义与变量类似，不同的是不能使用:=定义","categories":[{"name":"golang","slug":"golang","permalink":"http://www.badwolfbay.cn/categories/golang/"}],"tags":[]},{"title":"Ubuntu及mac下安装配置openvpn客户端","slug":"ubuntu-e4-b8-8b-e5-ae-89-e8-a3-85-e9-85-8d-e7-bd-aeopenvpn-e5-ae-a2-e6-88-b7-e7-ab-af","date":"2017-08-28T06:00:00.000Z","updated":"2017-09-19T16:22:22.000Z","comments":true,"path":"2017/08/28/ubuntu-e4-b8-8b-e5-ae-89-e8-a3-85-e9-85-8d-e7-bd-aeopenvpn-e5-ae-a2-e6-88-b7-e7-ab-af/","link":"","permalink":"http://www.badwolfbay.cn/2017/08/28/ubuntu-e4-b8-8b-e5-ae-89-e8-a3-85-e9-85-8d-e7-bd-aeopenvpn-e5-ae-a2-e6-88-b7-e7-ab-af/","excerpt":"","text":"Ubuntu下安装1.安装openvpn客户端 sudo apt-get install openvpn 2.配置文件 复制认证所需要的文件(ca.crt xxxxx_client_vpn.ovpn xxxxx.crt xxxxx.key ta.key)到/etc/openvpn目录下 3.启动openvpn客户端 sudo openvpn /etc/openvpn/xxxxx_client_vpn.ovpn 注意：命令需要在/etc/openvpn目录下执行，否则可能出现No such file or directory错误 MAC下安装 MAC有tunnelblick软件进行图形化安装，下边主要是通过命令行安装 1.安装brew2.通过brew进行安装 brew install openvpn To have launchd start openvpn now and restart at startup（如果想要启动openvpn或者在启动时重启可以执行命令）: sudo brew services start openvpn 3.安装目录 /usr/local/Cellar/openvpn/2.4.3/ 4.在xxxxx_client_vpn.ovpn所在目录执行命令 sudo /usr/local/Cellar/openvpn/2.4.3/sbin/openvpn ./xxxxx_client_vpn.ovpn","categories":[{"name":"linux","slug":"linux","permalink":"http://www.badwolfbay.cn/categories/linux/"}],"tags":[]},{"title":"CentOS7安装nginx","slug":"centos7-e5-ae-89-e8-a3-85nginx","date":"2017-08-28T05:58:53.000Z","updated":"2017-09-19T13:32:49.000Z","comments":true,"path":"2017/08/28/centos7-e5-ae-89-e8-a3-85nginx/","link":"","permalink":"http://www.badwolfbay.cn/2017/08/28/centos7-e5-ae-89-e8-a3-85nginx/","excerpt":"","text":"CentOS7上通过yum的方式安装nginx: 1.增加CentOS 7 EPEL repository sudo yum install -y epel-release 2.安装nginx sudo yum install -y nginx 3.启动nginx服务 sudo systemctl start nginx 4.如果在docker中安装nginx，Dockerfile如下： 1234567FROM cenos:7CMD yum install -y epel-releaseCMD yum install -y nginxENTRYPOINT [\"nginx\", \"-g\", \"daemon off;\"] 在docker中不能使用systemctl start nginx命令启动nginx","categories":[{"name":"linux","slug":"linux","permalink":"http://www.badwolfbay.cn/categories/linux/"}],"tags":[]},{"title":"Jenkins插件开发","slug":"jenkins-e6-8f-92-e4-bb-b6-e5-bc-80-e5-8f-91","date":"2017-08-28T05:57:47.000Z","updated":"2017-11-01T06:17:23.000Z","comments":true,"path":"2017/08/28/jenkins-e6-8f-92-e4-bb-b6-e5-bc-80-e5-8f-91/","link":"","permalink":"http://www.badwolfbay.cn/2017/08/28/jenkins-e6-8f-92-e4-bb-b6-e5-bc-80-e5-8f-91/","excerpt":"","text":"1.官网开发指南 https://wiki.jenkins.io/display/JENKINS/Plugin+tutorial 2.修改Maven的settting.xml文件 12345678910111213141516171819202122232425262728293031323334&lt;settings&gt; &lt;pluginGroups&gt; &lt;pluginGroup&gt;org.jenkins-ci.tools&lt;/pluginGroup&gt; &lt;/pluginGroups&gt; &lt;profiles&gt; &lt;!-- Give access to Jenkins plugins --&gt; &lt;profile&gt; &lt;id&gt;jenkins&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;!-- change this to false, if you don't like to have it on per default --&gt; &lt;/activation&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;repo.jenkins-ci.org&lt;/id&gt; &lt;url&gt;https://repo.jenkins-ci.org/public/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;repo.jenkins-ci.org&lt;/id&gt; &lt;url&gt;https://repo.jenkins-ci.org/public/&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;repo.jenkins-ci.org&lt;/id&gt; &lt;url&gt;https://repo.jenkins-ci.org/public/&lt;/url&gt; &lt;mirrorOf&gt;m.g.o-public&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;/mirrors&gt;&lt;/settings&gt; 3.创建新的插件，在命令行执行 mvn -U org.jenkins-ci.tools:maven-hpi-plugin:create 过程中要求输入插件的groupId和artifactId 编译新建的插件 mvn install 4.本地调试： set MAVEN_OPTS=-Xdebug -Xrunjdwp:transport=dt_socket,server=y,address=8000,suspend=n mvn hpi:run","categories":[{"name":"Java","slug":"Java","permalink":"http://www.badwolfbay.cn/categories/Java/"}],"tags":[]},{"title":"npm设置代理服务器","slug":"npm-e8-ae-be-e7-bd-ae-e4-bb-a3-e7-90-86-e6-9c-8d-e5-8a-a1-e5-99-a8","date":"2017-08-28T05:55:46.000Z","updated":"2017-09-19T14:01:46.000Z","comments":true,"path":"2017/08/28/npm-e8-ae-be-e7-bd-ae-e4-bb-a3-e7-90-86-e6-9c-8d-e5-8a-a1-e5-99-a8/","link":"","permalink":"http://www.badwolfbay.cn/2017/08/28/npm-e8-ae-be-e7-bd-ae-e4-bb-a3-e7-90-86-e6-9c-8d-e5-8a-a1-e5-99-a8/","excerpt":"","text":"1.设置代理命令 12npm config set proxy http://username:password@127.0.0.1:8080npm config set https-proxy http://username:password@127.0.0.1:8080 2.删除代理命令 12npm config delete https-proxynpm config delete proxy 3.查看代理设置 12npm config get proxynpm config get https-proxy","categories":[{"name":"nodejs","slug":"nodejs","permalink":"http://www.badwolfbay.cn/categories/nodejs/"}],"tags":[]},{"title":"Ubuntu以及MAC下安装配置openvpn客户端","slug":"ubuntu-e4-b8-8b-e5-ae-89-e8-a3-85-e9-85-8d-e7-bd-aeopenvpn-e5-ae-a2-e6-88-b7-e7-ab-af-trashed","date":"2017-08-22T14:25:41.000Z","updated":"2017-09-19T16:22:43.000Z","comments":true,"path":"2017/08/22/ubuntu-e4-b8-8b-e5-ae-89-e8-a3-85-e9-85-8d-e7-bd-aeopenvpn-e5-ae-a2-e6-88-b7-e7-ab-af-trashed/","link":"","permalink":"http://www.badwolfbay.cn/2017/08/22/ubuntu-e4-b8-8b-e5-ae-89-e8-a3-85-e9-85-8d-e7-bd-aeopenvpn-e5-ae-a2-e6-88-b7-e7-ab-af-trashed/","excerpt":"","text":"Ubuntu下安装1.安装openvpn客户端 sudo apt-get install openvpn 2.配置文件 复制认证所需要的文件(ca.crt xxxxx_client_vpn.ovpn xxxxx.crt xxxxx.key ta.key)到/etc/openvpn目录下 3.启动openvpn客户端 sudo openvpn /etc/openvpn/xxxxx_client_vpn.ovpn 注意：命令需要在/etc/openvpn目录下执行，否则可能出现No such file or directory错误 MAC下安装MAC有tunnelblick软件进行图形化安装，下边主要是通过命令行安装 1.安装brew2.通过brew进行安装 brew install openvpn To have launchd start openvpn now and restart at startup（如果想要启动openvpn或者在启动时重启可以执行命令）: sudo brew services start openvpn 3.安装目录 /usr/local/Cellar/openvpn/2.4.3/ 4.在xxxxx_client_vpn.ovpn所在目录执行命令 sudo /usr/local/Cellar/openvpn/2.4.3/sbin/openvpn ./xxxxx_client_vpn.ovpn","categories":[{"name":"linux","slug":"linux","permalink":"http://www.badwolfbay.cn/categories/linux/"}],"tags":[]},{"title":"CentOS7安装nginx","slug":"centos7-e5-ae-89-e8-a3-85nginx-trashed","date":"2017-08-22T13:52:56.000Z","updated":"2017-09-19T13:32:49.000Z","comments":true,"path":"2017/08/22/centos7-e5-ae-89-e8-a3-85nginx-trashed/","link":"","permalink":"http://www.badwolfbay.cn/2017/08/22/centos7-e5-ae-89-e8-a3-85nginx-trashed/","excerpt":"","text":"CentOS7上通过yum的方式安装nginx: 1.增加CentOS 7 EPEL repository sudo yum install -y epel-release 2.安装nginx sudo yum install -y nginx 3.启动nginx服务 sudo systemctl start nginx 4.如果在docker中安装nginx，Dockerfile如下： 1234567FROM cenos:7CMD yum install -y epel-releaseCMD yum install -y nginxENTRYPOINT [\"nginx\", \"-g\", \"daemon off;\"] 在docker中不能使用systemctl start nginx命令启动nginx","categories":[{"name":"linux","slug":"linux","permalink":"http://www.badwolfbay.cn/categories/linux/"}],"tags":[]}]}