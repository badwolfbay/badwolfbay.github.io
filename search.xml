<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[百度Java面试题汇总]]></title>
    <url>%2F2017%2F10%2F26%2Fjava-interview%2F</url>
    <content type="text"><![CDATA[简单记录下百度Java面试题 Java源码使用了哪些设计模式？列举你知道的类/包以及使用模式 写一个单例模式 Threadlocal有哪些特点，描述使用场景 快速排序 Mysql事务隔离级别(Spring事务隔离级别) 字符串常量池 类加载器 SpringMVC和Struts2有什么区别？(需要跟进新技术，为什么SpringMVC替代Struts2) Java，Python和Go三个相比各自有什么优点和缺点(需要自己总结思考) 网络传输,应用层有哪些协议?(并问了Http头的详细信息) 设计一个互联网架构 接上：当访问量多比如秒杀可能的瓶颈在哪里,怎么解决这些瓶颈问题 数据库怎么读写分离，怎么分库分表 Java中HashMap的containsKey和containsValue的时间复杂度 需要自己接下来深入学习JVM，网络层。由底层原理–&gt;架构–&gt;项目/应用/数据/性能]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go指南学习笔记十一]]></title>
    <url>%2F2017%2F10%2F25%2Fgo-tour-note-11%2F</url>
    <content type="text"><![CDATA[错误Go使用error来标识错误状态。同fmt.Stringer一样，error类型也是个内建接口。 123type error interface &#123; Error() string&#125; 通常函数会返回一个error值，调用它的代码应判断这个错误是否等于nil来进行错误处理。 1234567i, err := strconv.Atoi(&quot;42&quot;)if err ！= nil &#123; fmt.Printf(&quot;conldn&apos;t convert number: %v\n&quot;, err) return&#125;fmt.Printfln(&quot;Converted integer:&quot;, i) error为nil时表示成功；非nil的error表示错误 如：12345678910111213141516171819202122232425package mainimport ( &quot;fmt&quot; &quot;time&quot;)type MyError struct &#123; When time.Time What string&#125;func (e *MyError) Error() string &#123; return fmt.Sprintf(&quot;at %v, %s&quot;, e.When, e.What)&#125;func run() error &#123; return &amp;MyError&#123;time.Now(), &quot;it didn&apos;t work&quot;,&#125;&#125;func main() &#123; if err := run(); err != nil &#123; fmt.Println(err) // &#125;&#125; 运行输出结果：1at 2017-10-25 09:31:30.9208855 +0800 CST, it didn&apos;t work]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[非root用户运行docker]]></title>
    <url>%2F2017%2F10%2F13%2Fnot-root-run-docker%2F</url>
    <content type="text"><![CDATA[转载： 原文出处： https://notes.wanghao.work/2017-07-11-Docker非Root用户运行.html Docker Engine的Deamon进程是以root权限运行的，如果是普通用户要与之交互，需要使用sudo命令来提权与之交互。之前使用Docker官方的安装脚本安装完成之后，会给出一个提示将当前非root用户添加到doker组之中，以避免每次都需要输入sudo的麻烦。 然而随着Docker版本的迭代和官网的安装方式的更改，现在官方给出的安装方式是添加仓库源地址，然后使用默认的apt或者yum包管理工具来完成后安装。并不再提示用户添加非root用户到组。 默认情况下，完成Docker Engine的安装之后，Docker将会自动创建一个名为docker的用户组，所以root用户和在docker组中的用户都可以免去sudo来与Docker Engine交互。知道原理之后就简单了： 1sudo usermod -aG docker $&#123;whoami&#125; #添加当前用户到docker组]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go指南学习笔记十]]></title>
    <url>%2F2017%2F10%2F12%2Fgo-tour-note-10%2F</url>
    <content type="text"><![CDATA[Stringers普遍存在的接口是fmt包中定义的Stringer 123type Stringer inferface &#123; String() string&#125; Stringer是一个可以用字符串描述自己的类型。 12345678910111213141516171819package mainimport ( &quot;fmt&quot;)type Person struct &#123; Name string Age int&#125;func (p Person) String() string &#123; return fmt.Sprintf(&quot;%v (%v years)&quot;, p.Name, p.Age)&#125;func main() &#123; a := Person&#123;&quot;Dent&quot;, 42&#125; z := Person&#123;&quot;Foo&quot;, 90&#125; fmt.Println(a, z) // 输出Dent (42 years) Foo (90 years)&#125;]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes网络组件Calico安装]]></title>
    <url>%2F2017%2F09%2F26%2Fcalico-install-on-kubernetes%2F</url>
    <content type="text"><![CDATA[参照官网地址: https://docs.projectcalico.org/v2.5/getting-started/kubernetes/installation/integration Calico组件包括 calico/node， 必须安装在Master节点和每个计算节点上，包括BGP agent,负责网络策略。 cni/plugin， 和kubelet交互发现pod。 calico/policy-controller ,实现kubernetes的Network Policy API. 本文中安装的calico版本为2.5,对应的组件版本分别为: calicoctl:v1.5.0cni-plugin:v1.10.0cni:v0.3.0 安装calico/node12345$ wget https://github.com/projectcalico/calicoctl/releases/download/v1.5.0/calicoctl$ sudo chmod +x calicoctl$ mv calicoctl /usr/bin 创建calico-node.service 1$ vi /usr/lib/systemd/system/calico-node.service service的内容，需要将ETCD_ENDPOINTS中地址换成真实的etcd集群地址，可以将node-image中指定所需要的镜像名称，如果不指定，默认为quay.io/calico/node:latest 下边的命令会导致calio-node一直重启，所以需要换成官网的 123456789101112131415[Unit]Description=calicoctl nodeAfter=docker.serviceRequires=docker.service[Service]User=rootEnvironment=ETCD_ENDPOINTS=http://172.21.1.201:2379PermissionsStartOnly=trueExecStart=/usr/bin/calicoctl node run --node-image=calico/node:v2.5.1Restart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 换成(替换下边的ETCD_ENDPOINTS和ExecStart命令中的镜像名称) 12345678910111213141516171819202122232425262728293031[Unit]Description=calico nodeAfter=docker.serviceRequires=docker.service[Service]User=rootEnvironment=ETCD_ENDPOINTS=http://&lt;ETCD_IP&gt;:&lt;ETCD_PORT&gt;PermissionsStartOnly=trueExecStart=/usr/bin/docker run --net=host --privileged --name=calico-node \ -e ETCD_ENDPOINTS=$&#123;ETCD_ENDPOINTS&#125; \ -e NODENAME=$&#123;HOSTNAME&#125; \ -e IP= \ -e NO_DEFAULT_POOLS= \ -e AS= \ -e CALICO_LIBNETWORK_ENABLED=true \ -e IP6= \ -e CALICO_NETWORKING_BACKEND=bird \ -e FELIX_DEFAULTENDPOINTTOHOSTACTION=ACCEPT \ -v /var/run/calico:/var/run/calico \ -v /lib/modules:/lib/modules \ -v /run/docker/plugins:/run/docker/plugins \ -v /var/run/docker.sock:/var/run/docker.sock \ -v /var/log/calico:/var/log/calico \ calico/node:v2.5.1ExecStop=/usr/bin/docker rm -f calico-nodeRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 启动calico-node服务 12$ systemctl daemon-reload$ systemctl start calico-node 查看服务启动情况以及容器启动情况 123456789101112$ systemctl status calico-node● calico-node.service - calicoctl node Loaded: loaded (/usr/lib/systemd/system/calico-node.service; disabled; vendor preset: disabled) Active: activating (auto-restart) since Tue 2017-09-26 09:57:00 CST; 1s ago Process: 23696 ExecStart=/usr/bin/calicoctl node run --node-image=calico/node:v2.5.1 (code=exited, status=0/SUCCESS) Main PID: 23696 (code=exited, status=0/SUCCESS) $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1cca427ef1a1 calico/node:v2.5.1 &quot;start_runit&quot; 10 seconds ago Up 9 seconds calico-node 当calico-node的ExecStart配置成calicoctl run命令时会导致服务一直重启，如上表示服务未启动成功，名字为calico-node的容器会一直重启。按照如上所说的修改后，再次查看 12345678910111213141516171819$ systemctl status calico-node● calico-node.service - calicoctl node Loaded: loaded (/usr/lib/systemd/system/calico-node.service; disabled; vendor preset: disabled) Active: active (running) since Wed 2017-09-27 10:57:28 CST; 2min 4s ago Process: 21915 ExecStop=/usr/bin/docker rm -f calico-node (code=exited, status=0/SUCCESS) Main PID: 21949 (docker) Memory: 6.6M CGroup: /system.slice/calico-node.service └─21949 /usr/bin/docker run --net=host --privileged --name=calico-node -e ETCD_ENDPOINTS=http://172.21.1.201:2379 -e NODENAME= -e IP= -e NO_DEFAULT_POOLS= -e AS= -e CALICO_LIBNE...Sep 27 10:57:28 k1 systemd[1]: Started calicoctl node.Sep 27 10:57:28 k1 systemd[1]: Starting calicoctl node...Sep 27 10:57:28 k1 docker[21949]: Skipping datastore connection testSep 27 10:57:28 k1 docker[21949]: IPv4 address 172.21.1.200 discovered on interface eth0Sep 27 10:57:28 k1 docker[21949]: No AS number configured on node resource, using global valueSep 27 10:57:28 k1 docker[21949]: Using node name: k1Sep 27 10:57:29 k1 docker[21949]: time="2017-09-27T02:57:29Z" level=info msg="Loading config from environment"Sep 27 10:57:29 k1 docker[21949]: Starting libnetwork serviceSep 27 10:57:29 k1 docker[21949]: Calico node started successfully 安装calico/cni-plugin1234$ wget https://github.com/projectcalico/cni-plugin/releases/download/v1.10.0/calico$ wget https://github.com/projectcalico/cni-plugin/releases/download/v1.10.0/calico-ipam$ chmod +x calico calico-ipam$ mv calico calico-ipam /usr/bin cni-plugin需要标准的CNI配置文件，创建配置文件。 1234567891011121314151617181920$ mkdir -p /etc/cni/net.d$ cat &gt;/etc/cni/net.d/10-calico.conf &lt;&lt;EOF&#123; "name": "calico-k8s-network", "cniVersion": "0.1.0", "type": "calico", "etcd_endpoints": "http://172.21.1.201:2379", "log_level": "info", "ipam": &#123; "type": "calico-ipam", "k8s_api_root": "http://127.0.0.1:8080" &#125;, "policy": &#123; "type": "k8s" &#125;, "kubernetes": &#123; "kubeconfig": "/etc/cni/net.d/calico-kubeconfig" &#125;&#125;EOF 注意：policy选项为k8s,使用Kubernetes Network Policy来定义网络策略. 这里需要一个calico-kubeconfig的配置文件。在/etc/cni/net.d下创建calico-kubeconfig配置文件 12345678910111213141516# Kubeconfig file for Calico CNI plugin.apiVersion: v1kind: Configclusters:- name: local cluster: insecure-skip-tls-verify: true server: https://172.21.1.200:8080users:- name: calicocontexts:- name: calico-context context: cluster: local user: calicocurrent-context: calico-context 安装CNI plugin 123$ wget https://github.com/containernetworking/cni/releases/download/v0.3.0/cni-v0.3.0.tgz$ tar -zxvf cni-v0.3.0.tgz$ cp loopback /opt/cni/bin/ 安装calico networkpolicy-controller创建yaml文件，文件地址下载地址： https://docs.projectcalico.org/v2.5/getting-started/kubernetes/installation/policy-controller.yaml 内容如下:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# Calico Version v2.5.1# https://docs.projectcalico.org/v2.5/releases#v2.5.1# This manifest includes the following component versions:# calico/kube-policy-controller:v0.7.0# Create this manifest using kubectl to deploy# the Calico policy controller on Kubernetes.# It deploys a single instance of the policy controller.apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: calico-policy-controller namespace: kube-system labels: k8s-app: calico-policyspec: # Only a single instance of the policy controller should be # active at a time. Since this pod is run as a Deployment, # Kubernetes will ensure the pod is recreated in case of failure, # removing the need for passive backups. replicas: 1 strategy: type: Recreate template: metadata: name: calico-policy-controller namespace: kube-system labels: k8s-app: calico-policy spec: hostNetwork: true containers: - name: calico-policy-controller # Make sure to pin this to your desired version. image: quay.io/calico/kube-policy-controller:v0.7.0 env: # Configure the policy controller with the location of # your etcd cluster. - name: ETCD_ENDPOINTS value: &quot;&lt;ETCD_ENDPOINTS&gt;&quot; # Location of the Kubernetes API - this shouldn&apos;t need to be # changed so long as it is used in conjunction with # CONFIGURE_ETC_HOSTS=&quot;true&quot;. - name: K8S_API value: &quot;https://kubernetes.default:443&quot; # Configure /etc/hosts within the container to resolve # the kubernetes.default Service to the correct clusterIP # using the environment provided by the kubelet. # This removes the need for KubeDNS to resolve the Service. - name: CONFIGURE_ETC_HOSTS value: &quot;true&quot; 需要修改3处地址：image(镜像名称),ETCD_ENDPOINTS(ETCD地址),K8S_API(kubenetes 的API地址) 修改kubelet需要将kubelet中的网络指定为calico ,修改/usr/lib/system.d/system/kubelet.service，加入如下参数 123--network-plugin=cni--cni-conf-dir=/etc/cni/net.d--cni-bin-dir=/opt/cni/bin 注意：kubernetes1.4版本之前不支持cni-conf-dir和cni-bin-dir参数。替换成–network-plugin-dir=/etc/cni/net.d]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes上部署fluentd采集日志]]></title>
    <url>%2F2017%2F09%2F25%2Fkubernetes-fluentd%2F</url>
    <content type="text"><![CDATA[安装es集群假设es集群在k8s集群外,不要使用root用户。这里安装的版本是2.4.0 tar -zxvf elasticsearch-2.4.0.tar.gz 修改config文件夹下的elasticsearch.yml 12345678910cluster.name: elk_clusternode.name: elk_node01path.data: /csdbomc/elasticsearch-2.4.0/datapath.logs: /csdbomc/elasticsearch-2.4.0/logsnetwork.host: 172.21.0.201network.port: 9201http.cors.enabled : true //http.cors.allow-origin: "/.*/"http.cors.allow-methods : OPTIONS, HEAD, GET, POST, PUT, DELETEhttp.cors.allow-headers : "X-Requested-With,X-Auth-Token,Content-Type, Content-Length, Authorization" 到bin目录下执行（需要提前安装java） ./elasticsearch -d 制作fluent镜像Dockerfile内容如下: 123456789101112131415FROM badwolf/fluentd-es-image# Ensure there are enough file descriptors for running Fluentd.#RUN ulimit -n 65536# Disable prompts from apt.# Copy the Fluentd configuration file.COPY td-agent.conf /etc/td-agent/td-agent.confENV LD_PRELOAD /opt/td-agent/embedded/lib/libjemalloc.so# Run the Fluentd service.ENTRYPOINT ["td-agent"] td-agent.conf的内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307# This configuration file for Fluentd / td-agent is used# to watch changes to Docker log files. The kubelet creates symlinks that# capture the pod name, namespace, container name &amp; Docker container ID# to the docker logs for pods in the /var/log/containers directory on the host.# If running this fluentd configuration in a Docker container, the /var/log# directory should be mounted in the container.## These logs are then submitted to Elasticsearch which assumes the# installation of the fluent-plugin-elasticsearch &amp; the# fluent-plugin-kubernetes_metadata_filter plugins.# See https://github.com/uken/fluent-plugin-elasticsearch &amp;# https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter for# more information about the plugins.# Maintainer: Jimmi Dyson &lt;jimmidyson@gmail.com&gt;## Example# =======# A line in the Docker log file might look like this JSON:## &#123;"log":"2014/09/25 21:15:03 Got request with path wombat\n",# "stream":"stderr",# "time":"2014-09-25T21:15:03.499185026Z"&#125;## The time_format specification below makes sure we properly# parse the time format produced by Docker. This will be# submitted to Elasticsearch and should appear like:# $ curl 'http://elasticsearch-logging:9200/_search?pretty'# ...# &#123;# "_index" : "logstash-2014.09.25",# "_type" : "fluentd",# "_id" : "VBrbor2QTuGpsQyTCdfzqA",# "_score" : 1.0,# "_source":&#123;"log":"2014/09/25 22:45:50 Got request with path wombat\n",# "stream":"stderr","tag":"docker.container.all",# "@timestamp":"2014-09-25T22:45:50+00:00"&#125;# &#125;,# ...## The Kubernetes fluentd plugin is used to write the Kubernetes metadata to the log# record &amp; add labels to the log record if properly configured. This enables users# to filter &amp; search logs on any metadata.# For example a Docker container's logs might be in the directory:## /var/lib/docker/containers/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b## and in the file:## 997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b-json.log## where 997599971ee6... is the Docker ID of the running container.# The Kubernetes kubelet makes a symbolic link to this file on the host machine# in the /var/log/containers directory which includes the pod name and the Kubernetes# container name:## synthetic-logger-0.25lps-pod_default_synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log# -&gt;# /var/lib/docker/containers/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b-json.log## The /var/log directory on the host is mapped to the /var/log directory in the container# running this instance of Fluentd and we end up collecting the file:## /var/log/containers/synthetic-logger-0.25lps-pod_default_synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log## This results in the tag:## var.log.containers.synthetic-logger-0.25lps-pod_default_synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log## The Kubernetes fluentd plugin is used to extract the namespace, pod name &amp; container name# which are added to the log message as a kubernetes field object &amp; the Docker container ID# is also added under the docker field object.# The final tag is:## kubernetes.var.log.containers.synthetic-logger-0.25lps-pod_default_synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log## And the final log record look like:## &#123;# "log":"2014/09/25 21:15:03 Got request with path wombat\n",# "stream":"stderr",# "time":"2014-09-25T21:15:03.499185026Z",# "kubernetes": &#123;# "namespace": "default",# "pod_name": "synthetic-logger-0.25lps-pod",# "container_name": "synth-lgr"# &#125;,# "docker": &#123;# "container_id": "997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b"# &#125;# &#125;## This makes it easier for users to search for logs by pod name or by# the name of the Kubernetes container regardless of how many times the# Kubernetes pod has been restarted (resulting in a several Docker container IDs).## TODO: Propagate the labels associated with a container along with its logs# so users can query logs using labels as well as or instead of the pod name# and container name. This is simply done via configuration of the Kubernetes# fluentd plugin but requires secrets to be enabled in the fluent pod. This is a# problem yet to be solved as secrets are not usable in static pods which the fluentd# pod must be until a per-node controller is available in Kubernetes.# Prevent fluentd from handling records containing its own logs. Otherwise# it can lead to an infinite loop, when error in sending one message generates# another message which also fails to be sent and so on.&lt;match fluent.**&gt; type null&lt;/match&gt;# Example:# &#123;"log":"[info:2016-02-16T16:04:05.930-08:00] Some log text here\n","stream":"stdout","time":"2016-02-17T00:04:05.931087621Z"&#125;&lt;source&gt; type tail path /var/log/containers/*.log pos_file /var/log/es-containers.log.pos time_format %Y-%m-%dT%H:%M:%S.%NZ tag kubernetes.* format json read_from_head true&lt;/source&gt;# Example:# 2015-12-21 23:17:22,066 [salt.state ][INFO ] Completed state [net.ipv4.ip_forward] at time 23:17:22.066081&lt;source&gt; type tail format /^(?&lt;time&gt;[^ ]* [^ ,]*)[^\[]*\[[^\]]*\]\[(?&lt;severity&gt;[^ \]]*) *\] (?&lt;message&gt;.*)$/ time_format %Y-%m-%d %H:%M:%S path /var/log/salt/minion pos_file /var/log/es-salt.pos tag salt&lt;/source&gt;# Example:# Dec 21 23:17:22 gke-foo-1-1-4b5cbd14-node-4eoj startupscript: Finished running startup script /var/run/google.startup.script&lt;source&gt; type tail format syslog path /var/log/startupscript.log pos_file /var/log/es-startupscript.log.pos tag startupscript&lt;/source&gt;# Examples:# time="2016-02-04T06:51:03.053580605Z" level=info msg="GET /containers/json"# time="2016-02-04T07:53:57.505612354Z" level=error msg="HTTP Error" err="No such image: -f" statusCode=404&lt;source&gt; type tail format /^time="(?&lt;time&gt;[^)]*)" level=(?&lt;severity&gt;[^ ]*) msg="(?&lt;message&gt;[^"]*)"( err="(?&lt;error&gt;[^"]*)")?( statusCode=($&lt;status_code&gt;\d+))?/ path /var/log/docker.log pos_file /var/log/es-docker.log.pos tag docker&lt;/source&gt;# Example:# 2016/02/04 06:52:38 filePurge: successfully removed file /var/etcd/data/member/wal/00000000000006d0-00000000010a23d1.wal&lt;source&gt; type tail # Not parsing this, because it doesn't have anything particularly useful to # parse out of it (like severities). format none path /var/log/etcd.log pos_file /var/log/es-etcd.log.pos tag etcd&lt;/source&gt;# Multi-line parsing is required for all the kube logs because very large log# statements, such as those that include entire object bodies, get split into# multiple lines by glog.# Example:# I0204 07:32:30.020537 3368 server.go:1048] POST /stats/container/: (13.972191ms) 200 [[Go-http-client/1.1] 10.244.1.3:40537]&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\w\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\w)(?&lt;time&gt;\d&#123;4&#125; [^\s]*)\s+(?&lt;pid&gt;\d+)\s+(?&lt;source&gt;[^ \]]+)\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/kubelet.log pos_file /var/log/es-kubelet.log.pos tag kubelet&lt;/source&gt;# Example:# I1118 21:26:53.975789 6 proxier.go:1096] Port "nodePort for kube-system/default-http-backend:http" (:31429/tcp) was open before and is still needed&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\w\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\w)(?&lt;time&gt;\d&#123;4&#125; [^\s]*)\s+(?&lt;pid&gt;\d+)\s+(?&lt;source&gt;[^ \]]+)\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/kube-proxy.log pos_file /var/log/es-kube-proxy.log.pos tag kube-proxy&lt;/source&gt;# Example:# I0204 07:00:19.604280 5 handlers.go:131] GET /api/v1/nodes: (1.624207ms) 200 [[kube-controller-manager/v1.1.3 (linux/amd64) kubernetes/6a81b50] 127.0.0.1:38266]&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\w\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\w)(?&lt;time&gt;\d&#123;4&#125; [^\s]*)\s+(?&lt;pid&gt;\d+)\s+(?&lt;source&gt;[^ \]]+)\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/kube-apiserver.log pos_file /var/log/es-kube-apiserver.log.pos tag kube-apiserver&lt;/source&gt;# Example:# I0204 06:55:31.872680 5 servicecontroller.go:277] LB already exists and doesn't need update for service kube-system/kube-ui&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\w\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\w)(?&lt;time&gt;\d&#123;4&#125; [^\s]*)\s+(?&lt;pid&gt;\d+)\s+(?&lt;source&gt;[^ \]]+)\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/kube-controller-manager.log pos_file /var/log/es-kube-controller-manager.log.pos tag kube-controller-manager&lt;/source&gt;# Example:# W0204 06:49:18.239674 7 reflector.go:245] pkg/scheduler/factory/factory.go:193: watch of *api.Service ended with: 401: The event in requested index is outdated and cleared (the requested history has been cleared [2578313/2577886]) [2579312]&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\w\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\w)(?&lt;time&gt;\d&#123;4&#125; [^\s]*)\s+(?&lt;pid&gt;\d+)\s+(?&lt;source&gt;[^ \]]+)\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/kube-scheduler.log pos_file /var/log/es-kube-scheduler.log.pos tag kube-scheduler&lt;/source&gt;# Example:# I1104 10:36:20.242766 5 rescheduler.go:73] Running Rescheduler&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\w\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\w)(?&lt;time&gt;\d&#123;4&#125; [^\s]*)\s+(?&lt;pid&gt;\d+)\s+(?&lt;source&gt;[^ \]]+)\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/rescheduler.log pos_file /var/log/es-rescheduler.log.pos tag rescheduler&lt;/source&gt;# Example:# I0603 15:31:05.793605 6 cluster_manager.go:230] Reading config from path /etc/gce.conf&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\w\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\w)(?&lt;time&gt;\d&#123;4&#125; [^\s]*)\s+(?&lt;pid&gt;\d+)\s+(?&lt;source&gt;[^ \]]+)\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/glbc.log pos_file /var/log/es-glbc.log.pos tag glbc&lt;/source&gt;# Example:# I0603 15:31:05.793605 6 cluster_manager.go:230] Reading config from path /etc/gce.conf&lt;source&gt; type tail format multiline multiline_flush_interval 5s format_firstline /^\w\d&#123;4&#125;/ format1 /^(?&lt;severity&gt;\w)(?&lt;time&gt;\d&#123;4&#125; [^\s]*)\s+(?&lt;pid&gt;\d+)\s+(?&lt;source&gt;[^ \]]+)\] (?&lt;message&gt;.*)/ time_format %m%d %H:%M:%S.%N path /var/log/cluster-autoscaler.log pos_file /var/log/es-cluster-autoscaler.log.pos tag cluster-autoscaler&lt;/source&gt;&lt;filter kubernetes.**&gt; type kubernetes_metadata kubernetes_url http://172.21.1.200:8080&lt;/filter&gt;&lt;match **&gt; type elasticsearch log_level info include_tag_key true host 172.21.2.40 port 9211 logstash_format true # Set the chunk limit the same as for fluentd-gcp. buffer_chunk_limit 2M # Cap buffer memory usage to 2MiB/chunk * 32 chunks = 64 MiB buffer_queue_limit 32 flush_interval 5s # Never wait longer than 5 minutes between retries. max_retry_wait 30 # Disable the limit on the number of retries (retry forever). disable_retry_limit # Use multiple threads for processing. num_threads 8&lt;/match&gt; 修改其中的kubernetes_url地址为kubernetes的master节点地址修改host,port分别为es的地址和端口 部署fluent镜像使用daemonset部署fluent可以使得fluent在每台主机上部署一个POD cat fluentd-es.yaml 123456789101112131415161718192021222324252627282930313233343536apiVersion: extensions/v1beta1kind: DaemonSetmetadata: name: fluentd-es namespace: kube-system labels: k8s-app: fluentd-esspec: template: metadata: labels: k8s-app: fluentd-es spec: containers: - name: fluentd-es image: 172.21.3.106:5000/fluentd-es resources: limits: memory: 200Mi requests: cpu: 250m memory: 200Mi volumeMounts: - name: varlog mountPath: /var/log - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true terminationGracePeriodSeconds: 30 volumes: - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker镜像中国加速]]></title>
    <url>%2F2017%2F09%2F25%2Fdocker-image-mirror%2F</url>
    <content type="text"><![CDATA[通过 Docker 官方镜像加速，中国区用户能够快速访问最流行的 Docker 镜像。该镜像托管于中国大陆，本地用户现在将会享受到更快的下载速度和更强的稳定性，从而能够更敏捷地开发和交付 Docker 化应用。 Docker 中国官方镜像加速可通过 registry.docker-cn.com 访问。该镜像库只包含流行的公有镜像。私有镜像仍需要从美国镜像库中拉取。 您可以使用以下命令直接从该镜像加速地址进行拉取： 1$ docker pull registry.docker-cn.com/myname/myrepo:mytag 例如: 1$ docker pull registry.docker-cn.com/library/ubuntu:16.04 注: 除非您修改了 Docker 守护进程的 --registry-mirror 参数 (见下文), 否则您将需要完整地指定官方镜像的名称。例如，library/ubuntu、library/redis、library/nginx。 使用 –registry-mirror 配置 Docker 守护进程您可以配置 Docker 守护进程默认使用 Docker 官方镜像加速。这样您可以默认通过官方镜像加速拉取镜像，而无需在每次拉取时指定 registry.docker-cn.com。 您可以在 Docker 守护进程启动时传入 –registry-mirror 参数： 1$ docker --registry-mirror=https://registry.docker-cn.com daemon 为了永久性保留更改，您可以修改 /etc/docker/daemon.json 文件并添加上 registry-mirrors 键值。 123&#123; "registry-mirrors": ["https://registry.docker-cn.com"]&#125; 修改保存后重启 Docker 以使配置生效。 注: 您也可以使用适用于 Mac 的 Docker 和适用于 Windows 的 Docker 来进行设置。 原文连接: https://www.docker-cn.com/registry-mirror]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>image</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[调用Harbor RestAPI增加认证]]></title>
    <url>%2F2017%2F09%2F25%2Fharbor-api-token%2F</url>
    <content type="text"><![CDATA[1.通过Rest API访问Harbor需要Token认证信息 curl -u username:password http://172.21.1.19/api/users 但是通过restclient访问时像curl一样添加-u参数，需要在Header中增加参数 Authorization: Basic base64encoded(user:pass) 如： 123Builder builder = restClient.target(url + "/api/users").request();String auth = Base64.getEncoder().encodeToString("user:password".getBytes())；builder.header("Authorization","Basic " + auth); 在JAVA8中，可以直接使用Base64工具类。 参考链接: https://stackoverflow.com/questions/29116595/how-to-send-u-data-of-curl-in-rest-client]]></content>
      <categories>
        <category>harbor</category>
      </categories>
      <tags>
        <tag>harbor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MAC上安装docker]]></title>
    <url>%2F2017%2F09%2F21%2Finstall-docker-via-dlite%2F</url>
    <content type="text"><![CDATA[在MAC上安装docker for mac后，docker程序会在用户登录mac后自动启动，而如果用户没有登录，而是通过ssh远程登录的情况下，docker是无法启动的，在配置launchctl也无法配置自动启动命令。 经过一番搜索后，可以使用dlite来通过命令启动docker。 1.项目地址： https://github.com/nlf/dlite 2.在release中下载编译好的二进制文件，将文件放到PATH下，最简单的放到/usr/local/bin/目录下，然后执行 sudo dlite init 注意需要给dlite可执行权限 chmod +x dlite 3.执行命令后，开始询问创建虚拟机的参数，一路回车，但是最后报错 1234Saving configuration: doneCreating ssh key pair: doneAdding host to ssh config: ERROR!Adding host to ssh config: | open /var/root/.ssh/config: no such file or directory 手动创建.ssh目录以及config文件 sudo mkdir /var/root/.ssh sudo touch /var/root/.ssh/config 然后重新执行sudo dlite init 而后报新的错误 123Creating tool binaries: done Creating tool binaries: |Creating disk: ERROR!signal: trace/BPT trap 需要安装依赖 brew install opam golang libev opam init eval opam config env opam install uri qcow.0.7.0 conf-libev logs fmt qcow-format 然后仍然报错,信息 12Next we'll run a few steps that require sudo, you may be prompted for your password. Creating /etc/resoModifying /etc/exports: ERROR! done 根据github上的issue https://github.com/nlf/dlite/issues/218 问题在于执行sudo dlite init是不能加sudo,再次执行 dlite init 即可 dlite start 执行docker命令报错 12$ docker psError response from daemon: Unable to connect to the virtual machine 执行ssh docker@local.docker 报错。 正常Dlite 会自动添加 local.docker 到 OS X 的 hosts 文件内。 需要手动更改hosts文件 dlite ip 查看ip 为192.168.64.2 sudo vi /etc/hosts 增加一行 1192.168.64.2 local.docker 后执行docker ps就可以了 12$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 可参考链接 http://holys.im/2016/02/22/run-docker-on-osx-with-dlite/]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go 指南学习笔记九]]></title>
    <url>%2F2017%2F09%2F15%2Fgo-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b9-9d%2F</url>
    <content type="text"><![CDATA[1.接口，接口为一组方法定义的集合 和其它语言不同，类型实现接口不需要显示声明，不需要implements关键字 定义接口和实现接口互不依赖 1234567891011121314151617181920212223242526272829303132333435type Abser interface &#123; Abs() float64&#125;type MyFloat float64func (f MyFloat) Abs() float64 &#123; if f &lt; 0 &#123; return float64(-f) &#125; return float64(f)&#125;type Vertex struct &#123; X, Y float64&#125;func (v *Vertex) Abs() float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func main() &#123; var a Abser f := MyFloat(-math.Sqrt2) v := Vertex&#123;3, 4&#125; a = f // a MyFloat 实现了 Abser a = &amp;v // a *Vertex 实现了 Abser // 下面一行，v 是一个 Vertex（而不是 *Vertex） // 所以没有实现 Abser。 a = v fmt.Println(a.Abs())&#125;]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Go 指南学习笔记八]]></title>
    <url>%2F2017%2F09%2F11%2Fgo-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e5-85-ab%2F</url>
    <content type="text"><![CDATA[1.结构体方法 Go语言不像JAVA，没有类的定义，但是依然可以为结构体定义方法。 123456789101112131415package mainimport ( "fmt" "math")type Vertex struct &#123; X, Y float64&#125;func (v *Vertex) Abs() float64 &#123; return math.Sqrt(v.X * v.X + v.Y * v.Y)&#125;func main()&#123; v := &amp;Vertex&#123;3,4&#125; fmt.Println(v.Abs()) // 5&#125; 2.还可以对包内任意类型定义任意方法，但是不能对包外的类型或者基础类型定义方法 1234567891011121314151617181920package mainimport ( "fmt" "math")type MyFloat float64func (f MyFloat) Abs() float64 &#123; if f &lt; 0 &#123; return float64(-f) &#125; return float64(f)&#125;func main()&#123; f := MyFloat(-math.Sqrt2) fmt.Println(f.Abs()) // 1.4142135623730951&#125; 3.方法可以与类型和类型的指针相关联 如1中的Abs方法是作用的*Vertex指针类型上 1234func (v *Vertex) Scale(f float64)&#123; v.X = v.X * f v.Y = v.Y * f&#125; 与 1234func (v Vertex) Scale(f float64)&#123; v.X = v.X * f v.Y = v.Y * f&#125; 的区别 v := *Vertex(3,5) v.Scale(5) 前边的是用*Vertex指针类型接受，是引用传递，所以会改变接受者v的原始值，而后边的是用变量（后者说是对象）接受，是值传递，会对v进行一份copy,而不会对原始值做更改。]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Go 指南学习笔记七]]></title>
    <url>%2F2017%2F09%2F07%2Fgo-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b8-83%2F</url>
    <content type="text"><![CDATA[闭包 函数也是一个值，也可以像其它值一样传递。函数值也可以作为参数或者返回值 闭包是一个函数值，他引用了函数体之外的变量 这个函数值可以对引用的变量进行修改或者赋值 1234567891011121314151617181920package mainimport ( "fmt")func adder() func(int) int &#123; sum := 0 return func(x int) int &#123; sum += x return sum &#125;&#125;func main() &#123; pos, neg := adder(), adder() for i := 0; i &lt; 10; i++ &#123; fmt.Println(pos(i), neg(-2*i)) &#125;&#125; 输出结果： 12345678910111213[Running] go run "/Users/badwolf/Documents/go/hello/tempCodeRunnerFile.go"0 01 -23 -66 -1210 -2015 -3021 -4228 -5636 -7245 -90[Done] exited with code=0 in 0.605 seconds]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[zookeeper安装]]></title>
    <url>%2F2017%2F09%2F06%2Fzookeeper-e5-ae-89-e8-a3-85%2F</url>
    <content type="text"><![CDATA[1.下载安装文件，下载地址：http://mirrors.hust.edu.cn/apache/zookeeper/ 这里的下载的版本为zookeeper-3.4.10.tar.gz 2.解压下载的安装文件 tar -zxvf&nbsp;zookeeper-3.4.10.tar.gz 3.修改配置文件 zookeeper-3.4.10/confmv zoo_sample.cfg zoo.cfg zoo.cfg可以根据需要修改配置信息,如clientPort=2181 4.启动zookeeper cd ../bin./zkServer.sh start 启动成功信息： ZooKeeper JMX enabled by default Using config: /root/zookeeper-3.4.10/bin/../conf/zoo.cfg Starting zookeeper … STARTED 查看端口占用信息： netstat -an|grep 2181 5.客户端连接测试 ./zkCli.sh -server 127.0.0.1 连接成功后执行help命令可以查看帮助命令 [zk: 127.0.0.1(CONNECTED) 0] help ZooKeeper -server host:port cmd args stat path [watch] set path data [version] ls path [watch] delquota [-n|-b] path ls2 path [watch] setAcl path acl setquota -n|-b val path history&nbsp; redo cmdno printwatches on|off delete path [version] sync path listquota path rmr path get path [watch] create [-s] [-e] path data acl addauth scheme auth quit&nbsp; getAcl path close&nbsp; connect host:port]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Go 指南学习笔记六]]></title>
    <url>%2F2017%2F09%2F05%2Fgo-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e5-85-ad%2F</url>
    <content type="text"><![CDATA[1.map map在使用之前必须使用make来创建，值为nil的map是空的，并且不能对它赋值 1234567891011121314151617package mainimport ( "fmt")type Vertex struct&#123; Lat, Long float64&#125;var m map[string]Vertexfunc main() &#123; m = make(map[string]Vertex) m["Bell Labs"] = Vertex&#123;40.68433, -74.39967&#125; fmt.Println(m["Bell Labs"])// &#123;40.68433 -74.39967&#125;&#125; 2.和结构体语法类似 12345var n = map[string]Vertex &#123; "Bell Labs": Vertex&#123;40.68433, -74.39967,&#125;, "Google":Vertex&#123;37.42202, -122.08408,&#125;,&#125;fmt.Println(n) //map[Bell Labs:&#123;40.68433 -74.39967&#125; Google:&#123;37.42202 -122.08408&#125;] 如果map的value值只是一个类型，可以在{}中将类型省略 1234var k = map[string]Vertex&#123; "Bell Labs": &#123;40.68433, -74.39967&#125;, "Google": &#123;37.42202, -122.08408&#125;,&#125; 3.修改map 插入或者修改元素: m[key] =&nbsp;elem 获得元素:&nbsp;elem = m[key] 删除元素: delete(m,key) 检测是否存在: elem, ok = m[key]]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Go 指南学习笔记五]]></title>
    <url>%2F2017%2F09%2F03%2Fgo-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-ba-94%2F</url>
    <content type="text"><![CDATA[1.数组：类型[n]T是有n个值的类型为T的数组 var a [10] int 变量a是一个有10个整数的数组。 数组不能改变大小 12345678910package mainimport "fmt"func main() &#123; var a [10]string a[0] = "hello" a[1] = "world" fmt.Println(a[0], a[1]) //hello world fmt.Println(a) // [hello world&#125; 2.slice(切片),[]T为一个类型为T的slice,len(s)返回切片s的长度 123456789101112131415s := []int&#123;2, 3, 5, 7, 11, 13&#125;fmt.Println("s == ", s)for i := 0; i &lt; len(s); i++ &#123; fmt.Printf("s[%d] = %d\n", i, s[i])&#125;//输出结果s == [2 3 5 7 11 13]s[0] = 2s[1] = 3s[2] = 5s[3] = 7s[4] = 11s[5] = 13 3.slice 可以包含任意的类型，包括另一个 slice。 123456game := [][] string&#123; []string&#123;"","",""&#125;, []string&#123;"","",""&#125;, []string&#123;"","",""&#125;,&#125; 4.对slice切片 s[lo:hi] // 包含lo元素，不包含hi元素 5.构造slice,slice由make创建，这会分配一个全是零值的数组并返回一个slice并指向这个数组 1a := make([]int, 5) 可以传递第三个参数来执行容量 1b := make([]int, 0 , 5) // len(b) = 0, cap(b) = 5 如： 1234567891011121314func printlnSlice(s string, x []int) &#123; fmt.Printf("%s len=%d, cap=%d %v\n", s, len(x), cap(x), x)&#125;func main() &#123; a := make([]int, 5) printlnSlice("a", a) // a len=5, cap=5 [0 0 0 0 0] b := make([]int, 0, 5) printlnSlice("b", b) // b len=0, cap=5 [] c := b[:2] printlnSlice("c", c) // c len=2, cap=5 [0 0] d := c[2:5] printlnSlice("d", d) //d len=3, cap=3 [0 0 0]&#125; 6.向slice结尾添加元素，append 1234var a []intappend(a, 0)append(a, 1)append(a, 2, 3, 4) 如果slice底层数组的不能分配更多的数组时，会自动分配一个更大的数组，返回的slice指向新的数组。 7.切片是数组之上的抽象数据类型。 初始化不同,切片不需要指定固定长度:var a [10]int//数组var a []int//切片 切片的零值是nil 更多的slice切片：用法与本质]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Go 指南学习笔记四]]></title>
    <url>%2F2017%2F09%2F02%2Fgo-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e5-9b-9b%2F</url>
    <content type="text"><![CDATA[1.结构体struct 12345678910type Vertex struct &#123; X int Y int&#125;func main()&#123; v := Vertex&#123;1,2&#125; v.X = 4 fmt.Println(v.X) // 4&#125; 2.结构体指针 1234v := Vertex&#123;1,2&#125;p := &amp;amp;vp.X = 1e9fmt.Println(p.X) //1000000000 3.结构体语法，可以仅列出部分字段；&amp;可以指向结构体的指针 1234567var ( v1 = Vertex&#123;1, 2&#125; v2 = Vertex&#123;X: 1&#125; v3 = Vertex&#123;&#125; p = *Vertex&#123;1, 2&#125;)fmt.Println(v1, v2, v3, p)//&#123;1 2&#125; &#123;1 0&#125; &#123;0 0&#125; *&#123;1 2&#125;]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Go 指南学习笔记三]]></title>
    <url>%2F2017%2F09%2F01%2Fgo-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b8-89%2F</url>
    <content type="text"><![CDATA[1.指针：指针保存了变量的内存地址。 T是指向类型T的值指针，其零值是nil *符号会生成一个其作用对象的指针 12345678var p *intfmt.Println(p)i := 42p = *ifmt.Println(p) 输出结果为 *表示指针指向底层的值 1fmt.Println(*p) 并且可以通过修改指针修改底层的值 1*p = 21 这就是常说的”间接引用”。与C语言不同，go语言的指针没有运算。]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[利用Dockerhub+github自定义制作镜像]]></title>
    <url>%2F2017%2F08%2F31%2Fe5-88-a9-e7-94-a8dockerhubgithub-e8-87-aa-e5-ae-9a-e4-b9-89-e5-88-b6-e4-bd-9c-e9-95-9c-e5-83-8f%2F</url>
    <content type="text"><![CDATA[Dockerhub可以根据github工程中Dockerfile自动生成镜像，一般情况下，我们需要google下gcr的镜像，因为网络原因连接不上，我们可以将Dockerfile文件提交到github,然后生成我们自己的镜像，如： 前提是已经注册自己的Dockerhub帐号，登录https://hub.docker.com 点击右上角Create -&gt; Create Automated Build 后登录自己的github帐号 从自己的github工程中选择要创建镜像的工程 后输入要生成的镜像名称 在Build Setting的Tab页中输入Dockerfile的位置以及tag /目录为相对于github中工程的位置，如github中Dockerfile在/centos下 则输入/centos，再点击save changes后，点击Trigger后就可以构建镜像了，后续如果github中代码有更改，构建动作会自动触发。点击build details可以查看每次构建日志]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Go 指南学习笔记二]]></title>
    <url>%2F2017%2F08%2F30%2Fgo-e6-8c-87-e5-8d-97-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-ba-8c%2F</url>
    <content type="text"><![CDATA[1.for循环 go语言只有一个循环语句，即for. 1234sum := 0for i:= 0;i&lt;10;i++&#123; sum += i&#125; 不像java,python等，条件表达式不需要()小括号，循环体需要{} 初始化条件和后置判断条件不是必须的，如for ; i&lt;10; {} 在java等语言中while循环在go语言中写法 123for i &lt; 10 &#123; sum += i&#125; 死循环 123for &#123; sum += i&#125; 2.if语句 同for循环一样,if语句的判断条件语句也不需要() 12if i&lt;10 &#123;&#125; 同for循环一样，条件之前也可以是一个简单的语句 1234567i := 10if j := 10; i&lt;j &#123; return j&#125; else &#123; return i&#125; 3.switch语句 123456789101112131415161718package mainimport ( "fmt" "runtime")func main() &#123; fmt.Print("Go runs on ") switch os := runtime.GOOS; os &#123; case "darwin": fmt.Println("OS X.") case "linux": fmt.Println("Linux.") default: fmt.Printf("%s.", os) &#125;&#125; 按照条件从上到下执行，直到匹配到成功为止，执行成功后，后边的条件不再执行 没有条件的switch，如switch {},同switch true {}一样 4.defer语句 defer 语句会延迟函数的执行直到上层函数返回。 延迟调用的参数会立刻生成，但是在上层函数返回前函数都不会被调用 12345678package mainimport "fmt";func main()&#123; defer fmt.Println("world&amp;quot;) fmt.Print("hello")&#125; defer栈，延迟的函数调用会被压入一个栈中。 1234567891011package mainimport "fmt"func main() &#123; fmt.Println("counting") for i := 0; i &lt; 10; i++ &#123; defer fmt.Println(i) &#125; fmt.Println("done")&#125; 输出结果如下： 12345678910111213[Running] go run "/Users/badwolf/Documents/go/hello/defer.go"countingdone9876543210]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ssh免密码登陆]]></title>
    <url>%2F2017%2F08%2F30%2Fssh-e5-85-8d-e5-af-86-e7-a0-81-e7-99-bb-e9-99-86%2F</url>
    <content type="text"><![CDATA[有三台机器172.21.3.124/125/126，需要在这三台机器配置免密码登陆能够互相访问 1.在一台机器上执行命令，如172.21.3.124，期间会输入三次回车 ssh-keygen -t rsa 2.命令会在当前用户的家目录的.ssh的目录下生成id_rsa和id_rsa.pub文件，将id_rsa.pub文件copy到其他主机(172.21.3.125)的.ssh/authorized_keys目录下 因为我的是root用户，所以copy到/root/.ssh目录下。 3.这样再登陆172.21.3.125就可以不用输入密码了。需要注意的是 authorized_keys的权限需要是600。(chmod 600 .ssh/authorized_keys) 将id_rsa.pub文件Copy到172.21.3.126上就可以免密码登陆到172.21.3.126了。 将以上的命令和步骤重复在172.21.3.125/126分别执行， 注意已经存在authorized_keys文件不能覆盖，需要在文件内容后追加其他主机的id_rsa.pub的内容。 这样就可以三台机器 间互相免密码访问了。]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python *args **kwargs理解]]></title>
    <url>%2F2017%2F08%2F29%2Fpython-args-kwargs-e7-90-86-e8-a7-a3%2F</url>
    <content type="text"><![CDATA[*args表示任意多个无名参数，是个tuple（元组） **kwargs表示关键字参数，是个dict（字典） 这两个是python中的可变参数 注意：同时使用args和**kwargs时，args参数必须在**kwargs前边 123456789def foo(*args, **kwargs): print 'args = ', args print 'kwargs = ', kwargs if name == '__main__': foo(1,2,3,4) foo(a=1, b=2, c=3, d=4) foo(1,2,3,4,a=1, b=2, c=3, b=4) foo('a', 1, None, a=1, b='2', c=3)]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Go 指南学习笔记一]]></title>
    <url>%2F2017%2F08%2F28%2Fgolang-tour-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b8-80%2F</url>
    <content type="text"><![CDATA[Golang提供了官方的学习手册，tour地址：https://tour.go-zh.org同时，鉴于国内的网络环境，可以自己安装进行离线访问Go指南 1go get github.com/Go-zh/tour/gotour 然后就可以得到go tour了 12cd $GOPATH/bin./gotour 2.包 每个 Go 程序都是由包组成的。 程序运行的入口是包 main 。 一般情况下，包名与导入路径的最后一个目录一致。 3.包的导入 12import "fmt"import "math" 或者更多时候是下面的导入形式 1234import ( "fmt" "math") 4.大小写 首字母大写的名字是被导出的，可以被其他包引用，名称为小写的名称不会被导出 如： 可以引用fmt.Println()，而不能是fmt.println() 5.函数定义 123func add(x int, y int) int&#123; return x + y&#125; Golang和其他语言不同，变量名在类型之前,函数返回值再最后。 如果参数类型相同，则可以合并，如上可以写成 x, y int 。 函数返回值可以返回多个，形式为(int, int) 6.变量定义 var x ,y 可以定义在包级别或者函数级别。 函数赋值var x int = 1,可以省略类型，如var x = 1。 更可以简写成x :=1,这种情况下不能在函数外使用。 变量在没有初始化为默认为零值： 数值类型为 0 ， 布尔类型为 false ， 字符串为 &quot;&quot; （空字符串）不同类型之间的转换需要显示转换,如 int(i) 7.常量 常量定义与变量类似，不同的是不能使用:=定义]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu及mac下安装配置openvpn客户端]]></title>
    <url>%2F2017%2F08%2F28%2Fubuntu-e4-b8-8b-e5-ae-89-e8-a3-85-e9-85-8d-e7-bd-aeopenvpn-e5-ae-a2-e6-88-b7-e7-ab-af%2F</url>
    <content type="text"><![CDATA[Ubuntu下安装1.安装openvpn客户端 sudo apt-get install openvpn 2.配置文件 复制认证所需要的文件(ca.crt xxxxx_client_vpn.ovpn xxxxx.crt xxxxx.key ta.key)到/etc/openvpn目录下 3.启动openvpn客户端 sudo openvpn /etc/openvpn/xxxxx_client_vpn.ovpn 注意：命令需要在/etc/openvpn目录下执行，否则可能出现No such file or directory错误 MAC下安装 MAC有tunnelblick软件进行图形化安装，下边主要是通过命令行安装 1.安装brew2.通过brew进行安装 brew install openvpn To have launchd start openvpn now and restart at startup（如果想要启动openvpn或者在启动时重启可以执行命令）: sudo brew services start openvpn 3.安装目录 /usr/local/Cellar/openvpn/2.4.3/ 4.在xxxxx_client_vpn.ovpn所在目录执行命令 sudo /usr/local/Cellar/openvpn/2.4.3/sbin/openvpn ./xxxxx_client_vpn.ovpn]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装nginx]]></title>
    <url>%2F2017%2F08%2F28%2Fcentos7-e5-ae-89-e8-a3-85nginx%2F</url>
    <content type="text"><![CDATA[CentOS7上通过yum的方式安装nginx: 1.增加CentOS 7 EPEL repository sudo yum install -y epel-release 2.安装nginx sudo yum install -y nginx 3.启动nginx服务 sudo systemctl start nginx 4.如果在docker中安装nginx，Dockerfile如下： 1234567FROM cenos:7CMD yum install -y epel-releaseCMD yum install -y nginxENTRYPOINT ["nginx", "-g", "daemon off;"] 在docker中不能使用systemctl start nginx命令启动nginx]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Jenkins插件开发]]></title>
    <url>%2F2017%2F08%2F28%2Fjenkins-e6-8f-92-e4-bb-b6-e5-bc-80-e5-8f-91%2F</url>
    <content type="text"><![CDATA[1.官网开发指南 https://wiki.jenkins.io/display/JENKINS/Plugin+tutorial 2.修改Maven的settting.xml文件 12345678910111213141516171819202122232425262728293031323334&lt;settings&gt; &lt;pluginGroups&gt; &lt;pluginGroup&gt;org.jenkins-ci.tools&lt;/pluginGroup&gt; &lt;/pluginGroups&gt; &lt;profiles&gt; &lt;!-- Give access to Jenkins plugins --&gt; &lt;profile&gt; &lt;id&gt;jenkins&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;!-- change this to false, if you don't like to have it on per default --&gt; &lt;/activation&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;repo.jenkins-ci.org&lt;/id&gt; &lt;url&gt;https://repo.jenkins-ci.org/public/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;repo.jenkins-ci.org&lt;/id&gt; &lt;url&gt;https://repo.jenkins-ci.org/public/&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;repo.jenkins-ci.org&lt;/id&gt; &lt;url&gt;https://repo.jenkins-ci.org/public/&lt;/url&gt; &lt;mirrorOf&gt;m.g.o-public&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;/mirrors&gt;&lt;/settings&gt; 3.创建新的插件，在命令行执行 mvn -U org.jenkins-ci.tools:maven-hpi-plugin:create 过程中要求输入插件的groupId和artifactId 编译新建的插件 mvn install 4.本地调试： set MAVEN_OPTS=-Xdebug -Xrunjdwp:transport=dt_socket,server=y,address=8000,suspend=n mvn hpi:run]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[npm设置代理服务器]]></title>
    <url>%2F2017%2F08%2F28%2Fnpm-e8-ae-be-e7-bd-ae-e4-bb-a3-e7-90-86-e6-9c-8d-e5-8a-a1-e5-99-a8%2F</url>
    <content type="text"><![CDATA[1.设置代理命令 12npm config set proxy http://username:password@127.0.0.1:8080npm config set https-proxy http://username:password@127.0.0.1:8080 2.删除代理命令 12npm config delete https-proxynpm config delete proxy 3.查看代理设置 12npm config get proxynpm config get https-proxy]]></content>
      <categories>
        <category>nodejs</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu以及MAC下安装配置openvpn客户端]]></title>
    <url>%2F2017%2F08%2F22%2Fubuntu-e4-b8-8b-e5-ae-89-e8-a3-85-e9-85-8d-e7-bd-aeopenvpn-e5-ae-a2-e6-88-b7-e7-ab-af-trashed%2F</url>
    <content type="text"><![CDATA[Ubuntu下安装1.安装openvpn客户端 sudo apt-get install openvpn 2.配置文件 复制认证所需要的文件(ca.crt xxxxx_client_vpn.ovpn xxxxx.crt xxxxx.key ta.key)到/etc/openvpn目录下 3.启动openvpn客户端 sudo openvpn /etc/openvpn/xxxxx_client_vpn.ovpn 注意：命令需要在/etc/openvpn目录下执行，否则可能出现No such file or directory错误 MAC下安装MAC有tunnelblick软件进行图形化安装，下边主要是通过命令行安装 1.安装brew2.通过brew进行安装 brew install openvpn To have launchd start openvpn now and restart at startup（如果想要启动openvpn或者在启动时重启可以执行命令）: sudo brew services start openvpn 3.安装目录 /usr/local/Cellar/openvpn/2.4.3/ 4.在xxxxx_client_vpn.ovpn所在目录执行命令 sudo /usr/local/Cellar/openvpn/2.4.3/sbin/openvpn ./xxxxx_client_vpn.ovpn]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装nginx]]></title>
    <url>%2F2017%2F08%2F22%2Fcentos7-e5-ae-89-e8-a3-85nginx-trashed%2F</url>
    <content type="text"><![CDATA[CentOS7上通过yum的方式安装nginx: 1.增加CentOS 7 EPEL repository sudo yum install -y epel-release 2.安装nginx sudo yum install -y nginx 3.启动nginx服务 sudo systemctl start nginx 4.如果在docker中安装nginx，Dockerfile如下： 1234567FROM cenos:7CMD yum install -y epel-releaseCMD yum install -y nginxENTRYPOINT ["nginx", "-g", "daemon off;"] 在docker中不能使用systemctl start nginx命令启动nginx]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
</search>
